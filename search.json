[{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://rodrodr.github.io/tenet/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://rodrodr.github.io/tenet/articles/tagging_texts.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Computer-Assisted Text Tagging","text":"many occasions need check presence certain keywords categories text. procedure commonplace Content Analysis Text Mining tasks. vignette provides brief guide tag texts using dictionaries R.","code":""},{"path":"https://rodrodr.github.io/tenet/articles/tagging_texts.html","id":"tagging-one-text-at-a-time","dir":"Articles","previous_headings":"","what":"Tagging one text at a time","title":"Computer-Assisted Text Tagging","text":"package tenet provides function tag one text time. function tag_text receives text dictionary arguments. dictionary must named list names categories elements keywords. code generate html file text keywords highlighted. results identify words appear text facilitate localization themes ideas can help uncover patterns. function also allow use dictionaries tag texts. dictionaries must named lists names categories elements keywords. case, keywords belonging category dictionary colored color. useful identify presence themes text. hovering mouse highlighted words, name main category displayed. Although useful, function tagText limited one text time include advanced attributes, count matches categories included paragraph, sentence, document. works text whole. Actions ordering, breaking smaller textual units (paragraphs sentences), aggregating larger (parties, parliamentary sessions, etc.) filtering possible.","code":"library(tenet)  # Select Adolfo Suarez inaugural speech text <- as.character(spa.inaugural$text[1])  # Highlight some keywords using a color for  # each word tagText(text,          keywords = c(\"politic\",                       \"acci\",                       \"conflict\",                       \"partid\",                       \"defensa\",                      \"fuerzas armadas\"),          palette = pal$cat.awtools.spalette.6,         font.size = 24,          title = \"Adolfo Suarez Inaugural Speech (1979)\",         margin = 400) library(quanteda)  # Creates a dictionary form some policy categories dic <- dictionary(     list(     economica=c(\"econom\",                \"inversion\",                \"empresa\",                \"desarroll\",                \"monetari\",                \"industri\",                \"agric\",                \"agrari\"),     fiscal=c(\"hacienda\",                \"gasto\",                \"impuest\",                \"presupuest\",                \"tribut\",                \"tasa\",                \"fiscal\"),     educacion=c(\"educa\",              \"profesor\",              \"docent\",              \"escuel\",              \"colegio\",              \"universi\",              \"formación\"),     sanidad=c(\"sanidad\",                \"salud\",                \"hospital\",                \"sanitari\",                \"médic\",                \"enfermer\",                \"salud\"),     medioambiente=c(\"sostenible\",                  \"cambio clima\",                  \"medioambient\",                  \"reciclaje\",                  \"ecológico\",                  \"límpia\",                  \"invernadero\",                  \"emisiones\",                  \"carbono\",                  \"plástico\",                  \"fósiles\")))  # Taggs the text using the dictionary tagText(text,          keywords = dic,          palette = pal$cat.cartocolor.prism.11,         font.size = 24,          title = \"Adolfo Suarez Inaugural Speech (1979)\",         margin = 400)"},{"path":"https://rodrodr.github.io/tenet/articles/tagging_texts.html","id":"tagging-the-whole-corpus","dir":"Articles","previous_headings":"","what":"Tagging the whole corpus","title":"Computer-Assisted Text Tagging","text":"function tagCorpus overcomes limits mentioned . function receives corpus dictionary arguments. divides documents subunits (sentences, paragraphs, etc.) tags . results stored data frame row corresponds subunit. Besides tagged text, table also displays category dictionary matches, list categories found paragraph, number matches categories found row. can resize text (“Paragraph”) column, sort values clicking name columns, filter values typing text search boxes column names. paragraphs main category “medioambiente”? typing “medio” search box, results filtered can inspect text deeper understanding content. can also check documents (example, Spanish Presidents) mention category “medioambiente” . Although vignette table fit screen, using source console, function enables users inspect results browser fullscreen (recommended best results). Despite simplicity, function tagCorpus powerful tool tag explore whole corpus using dictionaries. allows users inspect results detailed way, facilitating identification patterns, comparing documents, localization quantification coding categories text.","code":"# Create a corpus object with # the Spanish inaugural speeches cp <- corpus(spa.inaugural)  # Tag the corpus using the dictionary # and spliting each text into sentences tagCorpus(cp, dic, reshape.to=\"sentences\")"},{"path":"https://rodrodr.github.io/tenet/articles/text_and_time.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Text and Time","text":"vignette introduces analysis flows time textual data. Many corpora organized according sequential time: parliamentary sessions, discourses, social media posts, among others. cases, important analyze evolution words themes time. , present two ways examing time texts. first count frequency categories themes (based set kewords) time. second analyze salience different actors groups overall flow words.","code":""},{"path":"https://rodrodr.github.io/tenet/articles/text_and_time.html","id":"counting-words-over-time","dir":"Articles","previous_headings":"","what":"Counting words over time","title":"Text and Time","text":"function countKeywords allows users count frequency set dictionary keywords corpus time. function requires corpus, dictionary keywords, grouping variable. function return data frame frequency keyword group. following example, employ spa.sessions corpus, contains speeches Spanish Congress. aggregate speeches month count frequency two themes: “sexual violence” “democratic memory”.","code":"# Create a new variable in the dataset # containing the month of the session spa.sessions$mes <- substr(spa.sessions$session.date,1,7)  # Aggregate the texts by month ag <- aggregate(list(text=spa.sessions$speech.text),                 by=list(mes=spa.sessions$mes),                 FUN=paste,                  collapse=\"\\n\")  # Convert the new data into a corpus object library(quanteda) cs <- corpus(ag)  # Create a dictionary for sexual violence # and democratic memory dic <- dictionary(   list(\"violencia sexual\"=c(\"volencia sexual\",                             \"violencia machista\"),        \"memoria democrática\"=c(\"memoria democrática\",                                \"memoria histórica\") ))  # Count the number of matches by # category for each month ng <- countKeywords(cs,                      dic,                      group.var = \"mes\",                      rel.freq = TRUE,                      quietly = T)  # Aggregate the results by category ng <- aggregate(frequency~level1+groups,                  data=ng,                  FUN=sum)  # Multiply the values for 10 thousand # to improve chart readability ng$frequency <- round(ng$frequency*10000,1)  # Rename the columns names(ng) <- c(\"Keyword\",\"Time\",\"Density\")  # Create the plot library(ggplot2) library(ggthemes)  ggplot(data=ng,         aes(          x=Time,           y=Density,           group=Keyword,          color=Keyword))+   geom_line()+   theme_clean()+   theme(legend.position=\"bottom\",         axis.text.x = element_text(angle = 60,                                     vjust = 1,                                     hjust=1))+   labs(title=\"Relative frequency of themes\")+   ylab(\"Relative frequency (per 10,000 words)\")"},{"path":"https://rodrodr.github.io/tenet/articles/text_and_time.html","id":"salience-of-actors-over-time","dir":"Articles","previous_headings":"","what":"Salience of actors over time","title":"Text and Time","text":"Another strategy consists evaluating salience different actors groups overall flow words. function plotStream allows users visualize evolution salience different actors corpus time. function requires corpus, grouping variable, variable names actors. function return streamgraph evolution salience actor time. employ spa.sessions corpus analyze salience representatives Vox party Spanish Congress. select four salient representatives party plot evolution salience time.","code":"# Select the most salient representatives for  # the Vox party ag <- spa.sessions[         spa.sessions$rep.name%in%           c(\"Abascal Conde, Santiago\",             \"Espinosa de los Monteros de Simón, Iván\",             \"Olona Choclán, Macarena\",                             \"Ortega Smith-Molina, Francisco Javier\"),]  # Create a variable of month for smoothing the data ag$month <- substr(ag$session.date,3,7)  # Aggregate words by representative and month ag <- aggregate(     list(words=ag$speech.tokens),        by=list(         month=ag$month,          rep=ag$rep.name,          party=ag$rep.party),        sum,        na.rm=T)  # Order the data by month ag <- ag[order(ag$month),]  # Create the chart plotStream(ag,             x=\"month\",             y=\"words\",             group = \"rep\")"},{"path":"https://rodrodr.github.io/tenet/articles/text_as_network.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Texts as Networks","text":"can represent texts networks? vignette provides brief overview prepare data","code":""},{"path":[]},{"path":"https://rodrodr.github.io/tenet/articles/text_as_network.html","id":"social-network-analysis","dir":"Articles","previous_headings":"","what":"Social Network Analysis","title":"Texts as Networks","text":"SNA techniques plotNetCentrality","code":""},{"path":"https://rodrodr.github.io/tenet/articles/text_as_network.html","id":"visualizing-text-networks","dir":"Articles","previous_headings":"","what":"Visualizing text networks","title":"Texts as Networks","text":"One mode Bimodal networks plotNet","code":""},{"path":"https://rodrodr.github.io/tenet/articles/text_scanning.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Scanning for Words and Themes","text":"many occasions, necessary scan text entire corpora specific words themes. instance, researcher may want explore often parties refer “democracy” related terms manifestos speeches parliament. can also interested categories different emotions policy areas. present functions related three tasks procedures often used text analysis scan texts. : contextualization, salience, positioning. first shows words context, allowing users see used sentences paragraphs. resource particularly usefull determine degree ambiguity polysemy word. second shows importance words text corpus, either expressing weigth text comparing frequency different texts. feature particularly useful select texts identify dcouments relevant specific topic. third shows position words text corpus, allowing users see words distributed text corpus. feature particularly useful identify position words text corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/articles/text_scanning.html","id":"contextualizing-keywords-using-wordtree","dir":"Articles","previous_headings":"","what":"Contextualizing keywords using wordTree","title":"Scanning for Words and Themes","text":"function wordTree employs Google charts visualization show context keyword text corpus. function requires corpus keyword arguments. function return visualization keyword center words appear keyword. chart enables users click particular words explore relate keyword “libertad”. graph also sizes words according frequency corpus. expressions appearing frequently larger appearing less.","code":"#  Load the packages library(quanteda)  # Create a corpus with the inaugural discourses # of Spanish presidents cp <- corpus(spa.inaugural)  # Create a wordtree with the word \"libertad\" wordtree(corpus = cp,          keyword = \"libertad\",          height = 800)"},{"path":"https://rodrodr.github.io/tenet/articles/text_scanning.html","id":"salience-analysis","dir":"Articles","previous_headings":"","what":"Salience analysis","title":"Scanning for Words and Themes","text":"cases, users want determine texts contain given keyword frequently. Imagine set 10 thousand laws researchers just want analyze word “tax” prevalent. case, can use function tfRatio, term-frequency ratio provides us ratio frequency word text compared frequency word entire corpus. Therefore, values way one frequent text corpus one less common. instance, can use function tfRatio determine texts corpus cp contain words “machis” frequently entire corpus (machismo, machista): can verify matches last two presidents PSOE party: José Luís Rodríguez Zapatero Pedro Sánchez. functions perform opposite operation. look reference texts calculate relevance word. function plotKeyness calculates keyness words text corpus. keyness measure importance word text corpus. function requires corpus reference corpus. function return visualization words relevant corpus compared reference corpus. closer cero, less relevant word. contrary, cero, relevant word. Words center-left chart least salient. appear times particularly useful distinguish reference text texts corpus. Words located either top-right bottom-right salient. frequent reference text highly informative distinguish reference text texts corpus. employed words Podemos session nº 124 Spanish parliament represented blue: “violencias”, “feministas”, “impunidad”, “logotipo”, “Irene” (reference Minister Gender Equality, Irene Montero). relativelly less employed words Podemos represented red: “violencia”, “votos”, “derechos”, “sexual”, “libertad”,“votos”,“votación”, among others.","code":"library(quanteda) cp <- corpus(spa.inaugural)  # Calculate the ratio for those # texts with the root \"machis\" tt <- tfRatio(cp, \"machis\")  # Display the name of the documents # containing words starting with \"machis\" as.character(docid(cp)[tt > 0]) #> [1] \"Zapatero II\" \"Sánchez I\"   \"Sánchez II\"  \"Sánchez III\" # Selects the session no. 124 of the Spanish parliament # discussing the law againgst sexual violence. spa <- spa.sessions[spa.sessions$session.number==124,]  # Aggregate Spanish parliamentary speeches # by party re <- aggregate(list(text=spa$speech.text),                  by=list(rep.party=spa$rep.party),                 FUN=paste,                  collapse=\"\\n\")  # Create a corpus object with the speeches ci <- corpus(re)  # Group the corpus by party ci <- corpus_group(ci, groups = rep.party)  # Plot the keyness (log-odds ratio) of the words  # in the speeches plotKeyness(corpus = ci,             type = \"log\",              ref.cat = \"Podemos\",              title = \"\")"},{"path":"https://rodrodr.github.io/tenet/articles/text_scanning.html","id":"positional-analyses","dir":"Articles","previous_headings":"","what":"Positional analyses","title":"Scanning for Words and Themes","text":"cases, users want determine position word text corpus. instance, researcher may want determine position word “democracy” speeches Spanish parliament. function plotLexDiv generates lexical dispersion plot shows position word text corpus. function requires corpus keyword arguments. function return visualization position keyword text corpus.  graph employed dictionary highlight themes instead individual keywords:  Finally, can use functions filterWords plotSpike create lexical diversity plots large corpus. example, apply dictionary (democracia, igualdad, libertad) sessions Spanish parliament. First aggregate parliamentary speeches session create corpus object results. , create interactive plot function plotSpike shows position keywords corpus, colored group dictionary. plot shows 19,428 matches three categories dictionary total 262 parliamentary sessions. Since plot interactive includes large number elements, preferrable run code console copying code pasting console.","code":"# Create a lexical dispersion plot for # the word \"democracia\" in the  # inaugural speeches of Spanish presidents plotLexDiv(corpus = cp,            docvar = \"doc_id\",            keyword = \"democracia\") library(quanteda)  dic <- dictionary(   list(democracia=c(\"democracia\",\"democrát\"),        libertad=c(\"libertad\"),        igualdad=c(\"igualdad\",\"equidad\")) )  # Create a lexical dispersion plot for # the dictionary in the  # inaugural speeches of Spanish presidents plotLexDiv(corpus = cp,            docvar = \"doc_id\",            palette = pal$cat.awtools.spalette.6[1:3],            keyword = dic) ag <- aggregate(list(text=spa.sessions$speech.text),                 by=list(session=spa.sessions$session.number),                 FUN=paste,                  collapse=\"\\n\")  # Paste zeros to the number to allow # sorting the sessions ag$session[nchar(ag$session)==1] <-  paste0(\"00\", ag$session[nchar(ag$session)==1])  ag$session[nchar(ag$session)==2] <-  paste0(\"0\", ag$session[nchar(ag$session)==2])  # Create a corpus with the results cs <- corpus(ag, docid_field = \"session\")  # Search the keywords and their # position in each session ter <- filterWords(cs, dic)  # Plot the results plotSpike(data=ter,           legend.title=\"Tema:\",           title=\"Congreso de los Diputados - XIV Legislatura (2019-2023)\",           subtitle=\"Democracia, libertad e igualdad en los debates de los plenos.\",            svg.width =5,            svg.height = 5)"},{"path":"https://rodrodr.github.io/tenet/articles/thematic_coding.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Tools for Thematic Coding","text":"vignette, introduce functions act tools crafted assist thematic coding process. Thematic coding method used analyze qualitative data. involves identifying patterns themes data assigning codes themes. Thematic coding flexible intuitive method can used analyze wide range qualitative data, including interviews, focus groups, open-ended survey responses. , employ dictionaries search terms ideas corpus, count frequency terms, organize results data frame different visualizations. focus put three tasks: Counting frequency terms dictionary corpus. Describe de prevalence categories comparatively mutual association. Assess different groups documents (organized President, party, variable) differ terms frequency categories dictionary.","code":""},{"path":"https://rodrodr.github.io/tenet/articles/thematic_coding.html","id":"counting-categories","dir":"Articles","previous_headings":"","what":"Counting categories","title":"Tools for Thematic Coding","text":"functions crafted count frequency: countKeywords forceDirectedTree - visualizing relevance categories. plotVoronoiTree","code":""},{"path":"https://rodrodr.github.io/tenet/articles/thematic_coding.html","id":"association-between-categories","dir":"Articles","previous_headings":"","what":"Association between categories","title":"Tools for Thematic Coding","text":"matchCodes - function calculates association categories dictionary. returns matrix number documents pair categories co-occur. function also returns matrix number documents category appears. generates data.frame object containing three variables: term1, term2, value. term1 term2 variables represent pair categories available dictionary, value variable represents number times categories co-occur corpus. chordDiagram - function generates chord diagram visualize association categories. function takes input output matchCodes function generates chord diagram using circlize package. function allows user customize appearance chord diagram specifying colors categories width chords. BubbleGrid chart variation bubble chart uses grid layout display bubbles. BubbleGrid chart useful visualizing distribution categories across different groups documents association . size bubbles represents frequency categories, color bubbles represents groups documents. BubbleGrid chart effective way compare distribution categories across different groups documents identify patterns trends data.","code":""},{"path":"https://rodrodr.github.io/tenet/articles/thematic_coding.html","id":"comparing-groups","dir":"Articles","previous_headings":"","what":"Comparing groups","title":"Tools for Thematic Coding","text":"sankeyDiagram - function generates Sankey diagram visualize distribution categories across different groups documents. function takes input output countKeywords function generates Sankey diagram using networkD3 package. function allows user customize appearance Sankey diagram specifying colors categories groups. BubbleGrid chart.","code":""},{"path":"https://rodrodr.github.io/tenet/articles/visualizing_text.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Visualizing Textual Data","text":"vignette wrapper introduce functions included tenet allow visualization text textual data. , , also included articles detailed explanations. Therefore, interested specific function, can check corresponding article.","code":""},{"path":"https://rodrodr.github.io/tenet/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rodrigo Rodrigues-Silveira. Author, maintainer.","code":""},{"path":"https://rodrodr.github.io/tenet/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Rodrigues-Silveira R (2024). tenet: Text Mining Function Humanities Social Sciences. R package version 0.1.0, https://rodrodr.github.io/tenet/.","code":"@Manual{,   title = {tenet: Text Mining Function for the Humanities and the Social Sciences},   author = {Rodrigo Rodrigues-Silveira},   year = {2024},   note = {R package version 0.1.0},   url = {https://rodrodr.github.io/tenet/}, }"},{"path":"https://rodrodr.github.io/tenet/index.html","id":"tenet-","dir":"","previous_headings":"","what":"Text Mining Function for the Humanities and the Social Sciences","title":"Text Mining Function for the Humanities and the Social Sciences","text":"Tools textual analysis visualization Humanities Social Sciences.","code":""},{"path":"https://rodrodr.github.io/tenet/index.html","id":"package-installation","dir":"","previous_headings":"","what":"Package installation","title":"Text Mining Function for the Humanities and the Social Sciences","text":"install.packages(“devtools”) devtools::install_github(“rodrodr/tenet”)","code":""},{"path":"https://rodrodr.github.io/tenet/reference/Pirandello.html","id":null,"dir":"Reference","previous_headings":"","what":"Pirandello - Six Characters in Search of an Author — Pirandello","title":"Pirandello - Six Characters in Search of an Author — Pirandello","text":"dataset contains dialogues 1921 play Six Characters Search Author Italian writer (Nobel laureate) Luigi Pirandello. Spanish version contained translated 1926 Félix Azzati currently available Wikipedia.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/Pirandello.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pirandello - Six Characters in Search of an Author — Pirandello","text":"","code":"Pirandello"},{"path":"https://rodrodr.github.io/tenet/reference/Pirandello.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Pirandello - Six Characters in Search of an Author — Pirandello","text":"data.frame object following variables: Order numeric; order speech play. Personaje character; character responsible speech. Action character; Description actions, emotions gestures character immediately speech. text character; text speech.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/Pirandello.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Pirandello - Six Characters in Search of an Author — Pirandello","text":"Wikipedia: https://es.wikisource.org/wiki/Seis_personajes_en_busca_de_autor.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/Pirandello.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pirandello - Six Characters in Search of an Author — Pirandello","text":"","code":"# some operations on the corpus summary(Pirandello) #>      Order        Personaje            Accion              text           #>  Min.   :  1.0   Length:683         Length:683         Length:683         #>  1st Qu.:171.5   Class :character   Class :character   Class :character   #>  Median :342.0   Mode  :character   Mode  :character   Mode  :character   #>  Mean   :342.0                                                            #>  3rd Qu.:512.5                                                            #>  Max.   :683.0                                                            head(Pirandello) #>    Order             Personaje Accion #> 8      1 Descripcion de escena   <NA> #> 12     2 Descripcion de escena   <NA> #> 16     3 Descripcion de escena   <NA> #> 19     4 Descripcion de escena   <NA> #> 22     5 Descripcion de escena   <NA> #> 25     6 Descripcion de escena   <NA> #>                                                                                                                                                                                                                                                                                                                                                             text #> 8                                                                                                                                                                                                                                                                                                              Es de día, en el escenario de un teatro de verso. #> 12 NOTA BENE. La Comedia no tiene actos ni escenas. La representación se interrumpirá una primera vez, sin bajar el telón, cuando el Director de la Compañía y el primero de los Personajes se retiran para concertar la escenificación, desalojando entonces los actores el escenario; y una segunda vez, cuando por error, el maquinista dejará caer el telón. #> 16                                                                                                                  Al entrar los espectadores en el teatro, hallarán levantado el telón, casi obscuro y vacio el escenario, como durante el dia, sin bastidores ni decorado, para que desde el principio se reciba la impresión de un espectáculo no preparado. #> 19                                                                                                                                                                                                                                                                                                        La concha del apuntador, estará a un lado del boquete. #> 22                                                                                                                                                                                                                                 Al otro lado, cerca del proscenio, una mesita y una butaca con el respaldo hacia el público, para el Director de la Compañía. #> 25                                                                                                                                                                                                                                   Otras dos mesitas, una más grande y otra más pequeña, con algunas sillas en torno, por si son necesarias durante el ensayo."},{"path":"https://rodrodr.github.io/tenet/reference/br.films.html","id":null,"dir":"Reference","previous_headings":"","what":"Brazilian post-1984 Fictional Cinema — br.films","title":"Brazilian post-1984 Fictional Cinema — br.films","text":"dataset contains 260 Brazilian fictional films 1985 2023.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/br.films.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brazilian post-1984 Fictional Cinema — br.films","text":"","code":"br.films"},{"path":"https://rodrodr.github.io/tenet/reference/br.films.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Brazilian post-1984 Fictional Cinema — br.films","text":"corpus object following docvars: primaryTitle character; Main title Director character; Names directors Country character; Countries involved production imdbRating numeric; IMDB Rating film Poster character; URL Film's poster Decade character; decade film released","code":""},{"path":"https://rodrodr.github.io/tenet/reference/br.films.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Brazilian post-1984 Fictional Cinema — br.films","text":"OMDB.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/br.films.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Brazilian post-1984 Fictional Cinema — br.films","text":"","code":"# some operations on the corpus summary(br.films) #> Corpus consisting of 260 documents, showing 100 documents: #>  #>                                                  Text Types Tokens Sentences #>                              A Hora da Estrela (1985)    42     54         3 #>                       Kiss of the Spider Woman (1985)    23     28         2 #>                                 Filme Demência (1986)    35     46         2 #>                           A Cor do seu Destino (1986)    36     50         2 #>                                  Alma Corsária (1996)    27     29         2 #>                                     O Mandarim (1995)    36     48         1 #>                              Terra Estrangeira (1995)    26     34         2 #>                              A Ostra e o Vento (1997)    15     15         1 #>                                Baile Perfumado (1996)    25     29         1 #>                     O Que é Isso, Companheiro? (1997)    31     36         2 #>             Boleiros: Era Uma Vez o Futebol... (1998)    22     28         2 #>                          O Homem da Capa Preta (1986)    21     23         1 #>                                A Marvada Carne (1985)    33     37         2 #>                               Eternamente Pagú (1987)    36     47         2 #>                              Central do Brasil (1998)    31     34         1 #>                          Anahy de las Misiones (1997)    32     37         1 #>                                         Kenoma (1998)    10     10         1 #>                                          Festa (1989)    31     42         1 #>                                         Sábado (1995)    39     49         3 #>                               La serva Padrona (1999)    39     47         2 #>                                        Traição (1998)    38     47         2 #>                              Ação Entre Amigos (1998)    37     49         5 #>                               Natal da Portela (1988)    32     46         2 #>                                  O Efeito Ilha (1994)    35     50         2 #>                                         Amores (1998)    37     47         3 #>                                         Gêmeas (1999)    40     54         3 #>                                Lavoura Arcaica (2001)    30     36         2 #>                                         Amélia (2000)    35     44         3 #>                          A Festa de Margarette (2003)    21     23         2 #>                                Os três Zuretas (1998)    17     20         1 #>                            Que Bom Te Ver Viva (1989)    21     22         2 #>                          Bicho de Sete Cabeças (2000)    37     48         3 #>                               Tônica Dominante (2000)    42     54         2 #>                          O Auto da Compadecida (2000)    16     20         1 #>                 O Circo das Qualidades Humanas (2000)    41     55         3 #>                                        Urbania (2001)    22     26         2 #>                            Domésticas: O Filme (2001)    37     51         2 #>                              Abril Despedaçado (2001)    24     27         1 #>                               Nelson Gonçalves (2002)    38     45         2 #>                                      Carandiru (2003)    36     42         2 #>                                 O Homem do Ano (2003)    31     37         2 #>                                 Cidade de Deus (2002)    22     24         1 #>                                 A Barca do Sol (1987)    32     42         2 #>                      Houve uma Vez Dois Verões (2002)    39     48         2 #>                  Gilberto Gil - Kaya N'Gandaya (2002)    35     42         3 #>                                     Separações (2002)    23     26         2 #>                                        Meteoro (2006)    28     37         1 #>                             Narradores de Javé (2003)    33     46         2 #>                            O Homem Que Copiava (2003)    25     27         1 #>                        Lisbela e o Prisioneiro (2003)    36     49         2 #>                                  Casa de Areia (2005)    34     40         1 #>                     Cinema Aspirinas® e Urubus (2005)    19     20         1 #>                                 O Preço da Paz (2003)    26     35         1 #>                                   Ashes of God (2003)     9      9         1 #>                                       Cipriano (2001)    36     49         1 #>                                      Feminices (2004)    23     28         2 #>                                     SuperOutro (1989)    28     33         1 #>                                      A Máquina (2005)    39     56         4 #>                    Quanto Vale Ou É Por Quilo? (2005)    38     44         1 #>                           Depois Daquele Baile (2005)    30     40         2 #>                                      Carreiras (2005)    21     23         1 #>                               El baño del Papa (2007)    15     15         1 #>                               O Cheiro do Ralo (2006)    39     43         1 #>                                 A Outra Margem (2007)    34     48         2 #>            Acredite, um Espírito Baixou em Mim (2006)    36     53         3 #>                                 Linha de Passe (2008)    17     18         1 #>                                Tapete Vermelho (2005)    39     56         3 #>                                 O Céu de Suely (2006)    21     22         1 #>                                   Anjos do Sol (2006)    36     46         2 #>        O Ano em Que Meus Pais Saíram de Férias (2006)    23     25         1 #>                                 Tropa de Elite (2007)    29     30         1 #>                              Cidade dos Homens (2007)    36     40         1 #>       Turma da Mônica em uma Aventura no Tempo (2007)    35     51         2 #>                                        Romance (2008)    37     50         2 #>                     Saneamento Básico, O Filme (2007)    30     38         1 #>                O Livro Multicolorido de Karnak (2006)    11     11         1 #>                               Chega de Saudade (2007)    40     52         1 #>                                         Raia 4 (2019)    36     47         2 #>                                A Quarta Parede (2019)    41     53         2 #>                               Jesús de Nazaret (2019)    23     31         1 #>                   Divaldo: O Mensageiro da Paz (2019)    11     11         1 #>                                 Noche de fuego (2021)    19     20         1 #>                                       Estômago (2007)    39     53         3 #>                           Noite Escura da Alma (2019)    28     36         2 #>                                      Son of Ox (2019)    39     49         3 #>                    As Melhores Coisas do Mundo (2010)    18     19         1 #>                               O Filho do Homem (2019)    18     20         1 #>                          Meu Nome Não é Johnny (2008)    30     33         1 #>                                 Jovens Polacas (2019)    39     45         2 #>               Ainda Temos a Imensidão da Noite (2019)    34     41         2 #>                                      Valentina (2020)    32     34         1 #>  Aos Olhos de Ernesto (Through Ernesto's Eyes) (2019)    32     43         2 #>                                       Sertânia (2018)    26     28         2 #>                     Sambando nas Brasas, Morô? (2007)    40     53         3 #>                        Turma da Mônica: Lições (2021)    29     34         2 #>                                      Até o Fim (2020)    37     42         2 #>  Osmar, the First Slice of the Loaf: The Movie (2019)    40     45         2 #>                                Atrás da Sombra (2020)    32     46         3 #>                         A Morte Habita à Noite (2020)    31     37         2 #>                                     Vaga Carne (2019)    37     55         2 #>                                          primaryTitle #>                              A Hora da Estrela (1985) #>                       Kiss of the Spider Woman (1985) #>                                 Filme Demência (1986) #>                           A Cor do seu Destino (1986) #>                                  Alma Corsária (1996) #>                                     O Mandarim (1995) #>                              Terra Estrangeira (1995) #>                              A Ostra e o Vento (1997) #>                                Baile Perfumado (1996) #>                     O Que é Isso, Companheiro? (1997) #>             Boleiros: Era Uma Vez o Futebol... (1998) #>                          O Homem da Capa Preta (1986) #>                                A Marvada Carne (1985) #>                               Eternamente Pagú (1987) #>                              Central do Brasil (1998) #>                          Anahy de las Misiones (1997) #>                                         Kenoma (1998) #>                                          Festa (1989) #>                                         Sábado (1995) #>                               La serva Padrona (1999) #>                                        Traição (1998) #>                              Ação Entre Amigos (1998) #>                               Natal da Portela (1988) #>                                  O Efeito Ilha (1994) #>                                         Amores (1998) #>                                         Gêmeas (1999) #>                                Lavoura Arcaica (2001) #>                                         Amélia (2000) #>                          A Festa de Margarette (2003) #>                                Os três Zuretas (1998) #>                            Que Bom Te Ver Viva (1989) #>                          Bicho de Sete Cabeças (2000) #>                               Tônica Dominante (2000) #>                          O Auto da Compadecida (2000) #>                 O Circo das Qualidades Humanas (2000) #>                                        Urbania (2001) #>                            Domésticas: O Filme (2001) #>                              Abril Despedaçado (2001) #>                               Nelson Gonçalves (2002) #>                                      Carandiru (2003) #>                                 O Homem do Ano (2003) #>                                 Cidade de Deus (2002) #>                                 A Barca do Sol (1987) #>                      Houve uma Vez Dois Verões (2002) #>                  Gilberto Gil - Kaya N'Gandaya (2002) #>                                     Separações (2002) #>                                        Meteoro (2006) #>                             Narradores de Javé (2003) #>                            O Homem Que Copiava (2003) #>                        Lisbela e o Prisioneiro (2003) #>                                  Casa de Areia (2005) #>                     Cinema Aspirinas® e Urubus (2005) #>                                 O Preço da Paz (2003) #>                                   Ashes of God (2003) #>                                       Cipriano (2001) #>                                      Feminices (2004) #>                                     SuperOutro (1989) #>                                      A Máquina (2005) #>                    Quanto Vale Ou É Por Quilo? (2005) #>                           Depois Daquele Baile (2005) #>                                      Carreiras (2005) #>                               El baño del Papa (2007) #>                               O Cheiro do Ralo (2006) #>                                 A Outra Margem (2007) #>            Acredite, um Espírito Baixou em Mim (2006) #>                                 Linha de Passe (2008) #>                                Tapete Vermelho (2005) #>                                 O Céu de Suely (2006) #>                                   Anjos do Sol (2006) #>        O Ano em Que Meus Pais Saíram de Férias (2006) #>                                 Tropa de Elite (2007) #>                              Cidade dos Homens (2007) #>       Turma da Mônica em uma Aventura no Tempo (2007) #>                                        Romance (2008) #>                     Saneamento Básico, O Filme (2007) #>                O Livro Multicolorido de Karnak (2006) #>                               Chega de Saudade (2007) #>                                         Raia 4 (2019) #>                                A Quarta Parede (2019) #>                               Jesús de Nazaret (2019) #>                   Divaldo: O Mensageiro da Paz (2019) #>                                 Noche de fuego (2021) #>                                       Estômago (2007) #>                           Noite Escura da Alma (2019) #>                                      Son of Ox (2019) #>                    As Melhores Coisas do Mundo (2010) #>                               O Filho do Homem (2019) #>                          Meu Nome Não é Johnny (2008) #>                                 Jovens Polacas (2019) #>               Ainda Temos a Imensidão da Noite (2019) #>                                      Valentina (2020) #>  Aos Olhos de Ernesto (Through Ernesto's Eyes) (2019) #>                                       Sertânia (2018) #>                     Sambando nas Brasas, Morô? (2007) #>                        Turma da Mônica: Lições (2021) #>                                      Até o Fim (2020) #>  Osmar, the First Slice of the Loaf: The Movie (2019) #>                                Atrás da Sombra (2020) #>                         A Morte Habita à Noite (2020) #>                                     Vaga Carne (2019) #>                                              Director #>                                         Suzana Amaral #>                                        Hector Babenco #>                                    Carlos Reichenbach #>                                           Jorge Durán #>                                    Carlos Reichenbach #>                                        Júlio Bressane #>                         Walter Salles, Daniela Thomas #>                                       Walter Lima Jr. #>                          Paulo Caldas, Lírio Ferreira #>                                         Bruno Barreto #>                                         Ugo Giorgetti #>                                        Sergio Rezende #>                                         André Klotzel #>                                         Norma Bengell #>                                         Walter Salles #>                                          Sérgio Silva #>                                          Eliane Caffé #>                                         Ugo Giorgetti #>                                         Ugo Giorgetti #>                                        Carla Camurati #>  José Henrique Fonseca, Arthur Fontes, Cláudio Torres #>                                            Beto Brant #>                                  Paulo César Saraceni #>                                  Luís Alberto Pereira #>                                  Domingos de Oliveira #>                                   Andrucha Waddington #>                                Luiz Fernando Carvalho #>                                          Ana Carolina #>                                         Renato Falcão #>                                          Cecílio Neto #>                                           Lúcia Murat #>                                         Laís Bodanzky #>                                           Lina Chamie #>                                           Guel Arraes #>     Milton Alencar, Paulo Augusto Gomes, Jorge Moreno #>                                      Flavio Frederico #>                      Fernando Meirelles, Nando Olival #>                                         Walter Salles #>                                          Elizeu Ewald #>                                        Hector Babenco #>                                 José Henrique Fonseca #>                        Fernando Meirelles, Kátia Lund #>                                         Leon Hirszman #>                                         Jorge Furtado #>                              Lula Buarque de Hollanda #>                                  Domingos de Oliveira #>                                    Diego de la Texera #>                                          Eliane Caffé #>                                         Jorge Furtado #>                                           Guel Arraes #>                                   Andrucha Waddington #>                                         Marcelo Gomes #>                                         Paulo Morelli #>                          Andre Semenza, André Semenza #>                                       Douglas Machado #>                                  Domingos de Oliveira #>                                        Edgard Navarro #>                                           João Falcão #>                                        Sergio Bianchi #>                                      Roberto Bomtempo #>                                  Domingos de Oliveira #>                     César Charlone, Enrique Fernández #>                                         Heitor Dhalia #>                                     Luís Filipe Rocha #>                                          Jorge Moreno #>                         Walter Salles, Daniela Thomas #>                                  Luís Alberto Pereira #>                                          Karim Aïnouz #>                                         Rudi Lagemann #>                                         Cao Hamburger #>                                          José Padilha #>                                         Paulo Morelli #>         Mauricio de Sousa, Rodrigo Gava, André Passos #>                                           Guel Arraes #>                                         Jorge Furtado #>                                          M.M. Izidoro #>                                         Laís Bodanzky #>                                        Emiliano Cunha #>                                          Hudson Senna #>                                             Rafa Lara #>                                          Clovis Mello #>                                         Tatiana Huezo #>                                          Marcos Jorge #>                               Breno Castelo, Dan-Leal #>                      Haroldo Borges, Ernesto Molinero #>                                         Laís Bodanzky #>                                    Alexandre Machafer #>                                            Mauro Lima #>                                      Alex Levy-Heller #>                                        Gustavo Galvão #>                             Cássio Pereira dos Santos #>                                     Ana Luiza Azevedo #>                                         Geraldo Sarno #>                                          Elizeu Ewald #>                                        Daniel Rezende #>                              Glenda Nicácio, Ary Rosa #>                                           Ale McHaddo #>                                        Thiago Camargo #>                                        Eduardo Morotó #>                        Ricardo Alves Jr., Grace Passô #>                                                         Country imdbRating #>                                                          Brazil        7.3 #>                                           Brazil, United States        7.3 #>                                                          Brazil        7.3 #>                                                          Brazil        7.1 #>                                                          Brazil        7.1 #>                                                          Brazil        7.1 #>                                                Brazil, Portugal        7.4 #>                                                          Brazil        7.2 #>                                                          Brazil        7.3 #>                                           Brazil, United States        7.4 #>                                                          Brazil        7.3 #>                                                          Brazil        7.3 #>                                                          Brazil        7.1 #>                                                          Brazil        7.1 #>                                                  Brazil, France        8.0 #>                                               Brazil, Argentina        7.1 #>                                                          Brazil        7.4 #>                                                          Brazil        7.1 #>                                                          Brazil        7.2 #>                                                          Brazil        7.1 #>                                                          Brazil        7.2 #>                                                          Brazil        7.2 #>                                                  Brazil, France        7.2 #>                                                          Brazil        7.1 #>                                                          Brazil        7.3 #>                                                          Brazil        7.1 #>                                                          Brazil        7.6 #>                                                          Brazil        7.1 #>                                           Brazil, United States        7.1 #>                                                          Brazil        7.5 #>                                                          Brazil        7.1 #>                                                          Brazil        7.7 #>                                                          Brazil        7.5 #>                                                          Brazil        8.6 #>                                                          Brazil        7.3 #>                                                          Brazil        7.1 #>                                                          Brazil        7.1 #>                                     Brazil, France, Switzerland        7.6 #>                                                          Brazil        7.5 #>                                        Brazil, Argentina, Italy        7.5 #>                                                          Brazil        7.1 #>                                         Brazil, France, Germany        8.6 #>                                                          Brazil        7.6 #>                                                          Brazil        7.1 #>                                                          Brazil        7.2 #>                                                          Brazil        7.1 #>                       Brazil, Argentina, Puerto Rico, Venezuela        7.2 #>                                                  Brazil, France        7.3 #>                                                          Brazil        7.6 #>                                                          Brazil        7.6 #>                                                          Brazil        7.4 #>                                                          Brazil        7.3 #>                                                          Brazil        7.3 #>                                          United Kingdom, Brazil        7.8 #>                                                          Brazil        7.2 #>                                                          Brazil        7.1 #>                                                          Brazil        7.8 #>                                                          Brazil        7.6 #>                                                          Brazil        7.2 #>                                                          Brazil        7.2 #>                                                          Brazil        7.4 #>                                         Uruguay, Brazil, France        7.2 #>                                                          Brazil        7.3 #>                                                Portugal, Brazil        7.1 #>                                                          Brazil        7.6 #>                                                          Brazil        7.1 #>                                                          Brazil        7.1 #>                               Brazil, Germany, Portugal, France        7.1 #>                                                          Brazil        7.1 #>                                                          Brazil        7.4 #>                                Brazil, United States, Argentina        8.0 #>                                                          Brazil        7.2 #>                                                          Brazil        7.1 #>                                                          Brazil        7.1 #>                                                          Brazil        7.3 #>                                                          Brazil        8.0 #>                                                          Brazil        7.2 #>                                                          Brazil        8.7 #>                                                          Brazil        7.7 #>                            Mexico, United States, Spain, Brazil        8.9 #>                                                          Brazil        8.1 #>  Mexico, Germany, Brazil, Argentina, Switzerland, United States        7.3 #>                                                   Brazil, Italy        7.8 #>                                                          Brazil        7.2 #>                                                          Brazil        7.3 #>                                                          Brazil        7.2 #>                                                          Brazil        7.2 #>                                                          Brazil        7.2 #>                                                          Brazil        7.1 #>                                                 Brazil, Germany        7.1 #>                                                          Brazil        7.2 #>                                                          Brazil        8.1 #>                                                          Brazil        7.4 #>                                                          Brazil        7.2 #>                                                          Brazil        7.7 #>                                                          Brazil        7.6 #>                                                          Brazil        7.7 #>                                                          Brazil        7.1 #>                                                          Brazil        7.1 #>                                                          Brazil        7.8 #>                                                                                                                                              Poster #>                                                  https://m.media-amazon.com/images/M/MV5BMTIzNzExOTI4Nl5BMl5BanBnXkFtZTcwNjE4NjAzMQ@@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTUzOTg0MDEwOV5BMl5BanBnXkFtZTcwNTg1OTM2MQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMWQxOTVlYTctYTg3MS00ODhlLWI5M2QtMjg1YjZhMzY0ZjI1XkEyXkFqcGdeQXVyODY5NzM4Nzc@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMDlkNmQyZjEtYWZlMy00ZmJhLWI1ZTMtYTY2ZmNhMWE2ZTg4XkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BN2ZiY2I4MmUtNDJjMS00ZThlLTg5MjgtNjdhNTg3YjgyZDJiXkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNTcxN2NiYmEtM2I5Yi00MDcxLThhOWUtZTQwNTliNjJjZDAxXkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZmVhYTlhODUtY2NjMS00MDZmLWIwZWQtNmFlODQzODVlY2Q3XkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZmVmYTMxMzYtM2ViYS00ODU0LTlkOGYtMDgxZWY5NGU5ZjkzXkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMzMyNzY1YWItMzBiMS00ZDkyLWIzMGMtZjFiNTlhNDgxNGM0XkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNWYxNWFjNjgtYzM1OS00NDllLWEyN2EtNTBiZGRiOTA5MWYwXkEyXkFqcGdeQXVyMTQxNzMzNDI@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZGNiOWZmMGUtODBmNC00MmE0LWE4ZjAtNzA1NzU5NWQ2OWZkXkEyXkFqcGdeQXVyMTAwNDM3OA@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMGQ2NTAxZWYtZTNkZC00YThhLWI2Y2YtM2U5MTc2NmY2MGM3XkEyXkFqcGdeQXVyMTAwNDM3OA@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNGI5NjQzYWMtODNiNi00NzYzLWJiOGUtNGE3ODUxOTI3NDlmXkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZDcyNDQzNDktYTNmNS00YWZiLWE3NTgtMjVhZjdiZDU2NWY4XkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BODMxMTEyZmQtODU1OC00Y2I5LWI3NmMtOGFiZTcxNTVmOTQ5XkEyXkFqcGdeQXVyMTQxNzMzNDI@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYTNhYWUwMjEtYTU2My00MmQ0LTkxODktZTAzOWQ3NTgxMzY2XkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNDRhNjZiNGItZDE2NS00NWYzLTliMjktOGJiNmJhZmNlMTgyXkEyXkFqcGdeQXVyMTkzODUwNzk@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZTBiM2ViMmQtODM2YS00OTE3LWI2NTItNGI1MmE0NmVkM2MzXkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMGYzMmNlMDEtNWZmNi00MjA3LWE2Y2UtYjJmOWM1ZWFiZDJlXkEyXkFqcGdeQXVyOTU3ODk4MQ@@._V1_SX300.jpg #>          https://m.media-amazon.com/images/M/MV5BMjAwZThjMWYtODVlNC00NTJkLTgxMjAtMTlkZmYzMmE2MjI1L2ltYWdlXkEyXkFqcGdeQXVyMjU4MzEwNTU@._V1_SX300.jpg #>  https://m.media-amazon.com/images/M/MV5BMTAxNTE0ZTYtYWNmYy00NmNlLWE1MmItYjZlMDVhZTNkZTRkL2ltYWdlL2ltYWdlXkEyXkFqcGdeQXVyMTgzNjQyMjc@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYjBjYzM5ZWUtOTNkYS00YWNmLTkwZDQtOTE3NjMwZmI0Y2JiXkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZDUxZjgxNzAtNmRhZi00MmVmLWE0ZDAtMDM2NmVkZDMzMjMyXkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMjEwNTE1MTgwOF5BMl5BanBnXkFtZTcwOTQyOTEyMQ@@._V1_SX300.jpg #>          https://m.media-amazon.com/images/M/MV5BZjc5NzNhMDItNTQ5MS00Yjk2LTkyM2EtZjAyZGIxNmI5NTBjL2ltYWdlXkEyXkFqcGdeQXVyNzExNDkyMzY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNDBiMTZhZjItY2EzYS00ZjhkLTk3NGQtZGFiYTk5YjFlNjY2XkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTg2NzM4OTYxNF5BMl5BanBnXkFtZTcwNTExMjA0MQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZTExZTFlZDgtZDM0ZS00NTdiLWE2NzktMjRkNmFjZjBhOTEyXkEyXkFqcGdeQXVyMTkzODUwNzk@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BNDUxMzQ2MTc4Ml5BMl5BanBnXkFtZTcwMzY5MDEzMQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMTEzNWE5YWItMTU2ZC00NTBlLWJiODQtNDJiZTg0NjM1ZDU3XkEyXkFqcGdeQXVyNDY2NDMxNDY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMjU2ZjEwOTgtMmI1NC00MjQ5LThhNjItNTg4ZDJhODU0NDhlXkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BN2Y2MGE3OTUtMDhkZC00MmU1LTg5NTktYjExNGZmNjgzNjJiXkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZDY2Y2Q0OGEtODk2OS00Mjg3LTlkNGYtMWZmMjYyYWYyZmFmXkEyXkFqcGdeQXVyMTkzODUwNzk@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNTQwMDI4OWMtOWY3Mi00YzlmLTgzOTctOWI5NjY4ZGM0MTAzXkEyXkFqcGdeQXVyNDEyNjEzOTg@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BODRlYTdkZDgtNTQ3ZC00ZmM2LWE4YzYtOGY5OGU3MzJlZDdkXkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZTcyNmE2NGItNTBmMC00MTBiLWE0MzAtNjgxMTZiNmUyM2NiXkEyXkFqcGdeQXVyNDY2NDMxNDY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYjIxMWE4ZDMtZTNkNy00MjY3LWJjNzktNDU4OWYzNGNjNDc4XkEyXkFqcGdeQXVyMTQxNzMzNDI@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZjYyN2ExNDQtMzNiMy00NzQzLTkwNjctYTE4YWJhYmY4MzI4XkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BODk2NGRkYmEtM2ZjMC00ZWQ5LWI5NGQtN2M1YjMxMDFkZGJiXkEyXkFqcGdeQXVyOTU3ODk4MQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMmQzY2RmYzMtYzRiOS00ZTMzLTgxMGYtZjRkNzAzYjA2MmVkXkEyXkFqcGdeQXVyNDc2MTA2NDg@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMTIzNTllZGYtOTMxZC00ZjdhLTllZDgtMjI3NjNkNjdkZjc2XkEyXkFqcGdeQXVyNTc1NTQxODI@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BOTMwYjc5ZmItYTFjZC00ZGQ3LTlkNTMtMjZiNTZlMWQzNzI5XkEyXkFqcGdeQXVyNzkwMjQ5NzM@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYTZhOTBmNjktMTUzNS00NDk1LWFiNzAtMjllZTlkYjMxYThmXkEyXkFqcGdeQXVyNDY2NDMxNDY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYTU3MTY1ZTEtNDFhNC00ZDAzLThlNGUtNzI2ZDAzNDEwMmJkXkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNGUyM2IyOGEtMTdhYS00ZWY2LTlmZDgtYmJmZDBiODU0YTdlXkEyXkFqcGdeQXVyMTAxMzk4OTU2._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMTVmNTM5ZjItOGFjYi00Y2Y1LTlkZTEtMDNlZDMyYjFiOTM1XkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMjhjODU5ZDMtYzE2OS00OTQ3LWI0MWYtY2RmMmE3MjE3Njg3XkEyXkFqcGdeQXVyOTU3ODk4MQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZmI2MzcwOTYtNjYxYi00OWRlLTg0NWYtMTU5MDBkZjRkY2E4XkEyXkFqcGdeQXVyMTkzODUwNzk@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTcwOTExNzg0MV5BMl5BanBnXkFtZTcwMDI3ODgyMQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYjM1ZWQ0MjYtYjY0ZC00Y2Q1LWE2OTctNjhlM2ZkMmIyYWU0XkEyXkFqcGdeQXVyMTkzODUwNzk@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMjc1NTkxMzYyMF5BMl5BanBnXkFtZTcwMzY3ODIzMQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYWVkMmVmNjctYWEzMi00NzM4LTg4OTUtZDA0YjY5YzU5YmVhXkEyXkFqcGdeQXVyODc0Mzc3NDg@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYzhlNDJkNTAtMTY1Ni00MDE2LTk5ODctNWY5NTQ1NTc0MDRmXkEyXkFqcGdeQXVyNjU0MDU4OTg@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMjMxODYyMTIyNl5BMl5BanBnXkFtZTcwMDE3MjU1OQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNzJlZjA3NTctMWRjMi00YmJhLThkNGMtOTYxMTg0YjI1NjcwXkEyXkFqcGdeQXVyNDY2NDMxNDY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNjY0NTAzMTAtZmY0MC00YmJiLWE5YzctNGFiNjA0YzMxMDk3XkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMjRhNzc2NTUtZGE4MC00MzhiLWEwYTUtY2Q4Mzc0NDIxNTUwXkEyXkFqcGdeQXVyOTU3ODk4MQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMjNjMGMxNjItZjZmNy00ZWMzLWFhMmQtY2MzODRlYTU1MWM4XkEyXkFqcGdeQXVyMTkzODUwNzk@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMzQ5MzQwMzIxMF5BMl5BanBnXkFtZTgwMjkyNzIxNzE@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BOWMwZWYxN2MtYjZlOC00OTU5LTlhNzgtNGYzZTYwMzZlMzBhXkEyXkFqcGdeQXVyMTkzODUwNzk@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BODcwZTNjYjctOWZmYS00YjE5LWEwZDktM2ZmZDE1MDM4MWYzXkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTU2MzkwODQ4Nl5BMl5BanBnXkFtZTcwNzYyMTMzMg@@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTM4NjI0ODMzOF5BMl5BanBnXkFtZTcwMzk1OTQ2OA@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZjNhODQ1MWYtZGIzNi00NmUxLWExODktZjIzMjFlZTZlOTI4XkEyXkFqcGdeQXVyMjUyMTE3MTc@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BM2U1ZDU3ZWMtYzI4Zi00NzExLWExMmEtNTJjNWI4Zjg3ODFhXkEyXkFqcGdeQXVyMzU0NzkwMDg@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZmRlNzU3ZmEtOTBiOC00MDcyLTkyYTgtYWFlMDg0NTA1YjI0XkEyXkFqcGdeQXVyNDc2MTA2NDg@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTY1MDYyNjg4NV5BMl5BanBnXkFtZTcwMTg0NDA1NA@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMDA4ZmM4MjgtMmI2OS00MzBlLWE5YTEtMWUwZDYyNmYxNzVmXkEyXkFqcGdeQXVyNDc2MTA2NDg@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNDgyMDI1NjItMTI5Ny00OTQzLWE4MTgtMGIxMDVhNDQxY2NkXkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMWE1MDM2OTEtN2ZkMS00YzdhLWE5MWMtMzU3YmM5NWYyMzg2XkEyXkFqcGdeQXVyODc0OTEyNDU@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYmI1ODU5ZjMtNWUyNC00YzllLThjNzktODE1M2E4OTVmY2E5XkEyXkFqcGdeQXVyMTExNzQzMDE0._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTI4NTg4ODU0NF5BMl5BanBnXkFtZTcwNjA1MjU1MQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZGFkZDViOWEtOWNkNC00OWUxLWIxZDYtZGJhODZhZDAzMzY1XkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMzAzMjFiODktMDhkNi00NGZjLWJkYjktZjJkNjc3OTQ1N2VjXkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZGMzYjE4MzEtNTUzOC00OGQyLWI5YTUtYzc1ODU3M2NhOTQ2XkEyXkFqcGdeQXVyNDc2MTA2NDg@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMTM5OTA0NTgwOV5BMl5BanBnXkFtZTcwMjQwMzQyMg@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZmM3OGMyMmMtMzFkMS00YzY1LWJlNDQtYTNlYWYyZTVmMzU0XkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNjNiN2RhODktZjUwMS00YzUwLWEwNzItNjliZWNkYmYyZWQxXkEyXkFqcGdeQXVyNTM4NjQ3NQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMmIwZWQ1YzItZDM1OC00NTkyLWE1N2UtZjYxMTFmOWZhYjMzXkEyXkFqcGdeQXVyNDM5ODEyMDA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMjhiNWFiMjMtOGU4Yy00Mjg3LTkyYjgtZmIwNzkxOTdjZTcyXkEyXkFqcGdeQXVyNjE1MzUxMjA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMDQwMGYyNjYtNzA3MC00MDgwLTllNTUtNDU4MDVhZjE4NTliXkEyXkFqcGdeQXVyMTA3Mjc1MTcy._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYjFhNTQwMzMtNDIyZi00ZTRhLTgyYTQtMjlmOTc5MGU4NTI3XkEyXkFqcGdeQXVyMTAyMjQ3NzQ1._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMzI0MDY1YWYtN2RiNS00MzhkLWEyNjMtNTNiYWZiNzU1NTdhXkEyXkFqcGdeQXVyMjY4MTc1MDM@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNmQzZDNmNzUtODZiNS00ZTRiLTg4YWItYzVkZjBmOGUxYmE2XkEyXkFqcGdeQXVyNDY4Njc4MTY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMjZiNDNkZWQtNTYwOC00Y2JkLWEwYTQtNWY0NjQzODFmYTUxXkEyXkFqcGdeQXVyMTY3MTIwMTg@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNGMwMGY2MjYtNGMwZS00NDRmLWJlODMtZDA0Y2I4MWE2ZGQyXkEyXkFqcGdeQXVyMTY2MzYyNzA@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BYmUxMTk0MTEtOTY5Ny00NTE0LWI3MmUtYzExZWMwZDIxNjdiXkEyXkFqcGdeQXVyNzAxMjczMDc@._V1_SX300.jpg #>                                                  https://m.media-amazon.com/images/M/MV5BMjMzNTAxNjk4NF5BMl5BanBnXkFtZTcwNjQ3NDQ2OA@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNmRmNWJiNmUtZjgxNy00NDVjLTg1YWItMmM1ZmZmZDgwYWIzXkEyXkFqcGdeQXVyODMyNTg4MjY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZDM0ZmY5YjItYzRiOS00OTQwLWFlMzEtNjMzNzhiZGM1NDBjXkEyXkFqcGdeQXVyMTM0OTg2ODM@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMTY4MjJlZDktMDc2My00YjdhLThhNWQtZDI1ZTVhNjc2ODkwXkEyXkFqcGdeQXVyMjA5MDI0MzU@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNDg0NjEwNWMtMTY1Ni00MWMyLTgzYTItMzFhNTA0YTVjNzhiXkEyXkFqcGdeQXVyMTA4OTA1Mjg1._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZTBhMThkOWItMmU0ZS00ZmJlLThkNmQtM2ZjZGZlOGEwMTBlXkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BNmM1ZGUzMGYtNTA5NS00NGFmLTk0MDgtMmY0MzA5OWMzNDZiXkEyXkFqcGdeQXVyOTU3ODk4MQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZTBiNTZlMDgtMmFkNS00MDIzLThhOTctYTI0MWQwZmRiNzkzXkEyXkFqcGdeQXVyNzAwMjU2MTY@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMzRhNTY2ODgtMDQzMi00ZTUxLTkwMTUtYTlkNzRmNDY1MzM4XkEyXkFqcGdeQXVyMjAxMzY4NjU@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMGMxOGU5MTQtYTk0MS00ZWVkLTgzMjMtNTM2OWQ4ODdiNWY1XkEyXkFqcGdeQXVyOTU4MDAyMDg@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BOGZjZDA3OWYtMGQ5Yi00MTgzLTg1MjMtMWNkMDU3NzI5ZTczXkEyXkFqcGdeQXVyODY5Nzc1NQ@@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BZWIzMjcxM2EtOWUwZC00Yjg5LTk3ODctODIzNzhkZWFlNjgxXkEyXkFqcGdeQXVyMTMzODQ4NzQ@._V1_SX300.jpg #>                  https://m.media-amazon.com/images/M/MV5BMWIxY2Q0ODktMzg1OC00ZTQ2LThmMDgtMGNkMGU1YzYzNmZhXkEyXkFqcGdeQXVyNDgyMTE1MzM@._V1_SX300.jpg #>  Decade #>    1980 #>    1980 #>    1980 #>    1980 #>    1990 #>    1990 #>    1990 #>    1990 #>    1990 #>    1990 #>    1990 #>    1980 #>    1980 #>    1980 #>    1990 #>    1990 #>    1990 #>    1980 #>    1990 #>    1990 #>    1990 #>    1990 #>    1980 #>    1990 #>    1990 #>    1990 #>    2000 #>    2000 #>    2000 #>    1990 #>    1980 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    1980 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    1980 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2000 #>    2010 #>    2010 #>    2010 #>    2010 #>    2020 #>    2000 #>    2010 #>    2010 #>    2010 #>    2010 #>    2000 #>    2010 #>    2010 #>    2020 #>    2010 #>    2010 #>    2000 #>    2020 #>    2020 #>    2010 #>    2020 #>    2020 #>    2010 #>  head(quanteda::docvars(br.films)) #>                      primaryTitle           Director               Country #> 1        A Hora da Estrela (1985)      Suzana Amaral                Brazil #> 2 Kiss of the Spider Woman (1985)     Hector Babenco Brazil, United States #> 3           Filme Demência (1986) Carlos Reichenbach                Brazil #> 4     A Cor do seu Destino (1986)        Jorge Durán                Brazil #> 5            Alma Corsária (1996) Carlos Reichenbach                Brazil #> 6               O Mandarim (1995)     Júlio Bressane                Brazil #>   imdbRating #> 1        7.3 #> 2        7.3 #> 3        7.3 #> 4        7.1 #> 5        7.1 #> 6        7.1 #>                                                                                                                               Poster #> 1                                 https://m.media-amazon.com/images/M/MV5BMTIzNzExOTI4Nl5BMl5BanBnXkFtZTcwNjE4NjAzMQ@@._V1_SX300.jpg #> 2                                 https://m.media-amazon.com/images/M/MV5BMTUzOTg0MDEwOV5BMl5BanBnXkFtZTcwNTg1OTM2MQ@@._V1_SX300.jpg #> 3 https://m.media-amazon.com/images/M/MV5BMWQxOTVlYTctYTg3MS00ODhlLWI5M2QtMjg1YjZhMzY0ZjI1XkEyXkFqcGdeQXVyODY5NzM4Nzc@._V1_SX300.jpg #> 4 https://m.media-amazon.com/images/M/MV5BMDlkNmQyZjEtYWZlMy00ZmJhLWI1ZTMtYTY2ZmNhMWE2ZTg4XkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #> 5 https://m.media-amazon.com/images/M/MV5BN2ZiY2I4MmUtNDJjMS00ZThlLTg5MjgtNjdhNTg3YjgyZDJiXkEyXkFqcGdeQXVyMTU2ODc4ODQ@._V1_SX300.jpg #> 6 https://m.media-amazon.com/images/M/MV5BNTcxN2NiYmEtM2I5Yi00MDcxLThhOWUtZTQwNTliNjJjZDAxXkEyXkFqcGdeQXVyMTI0Nzk5NTQ2._V1_SX300.jpg #>   Decade #> 1   1980 #> 2   1980 #> 3   1980 #> 4   1980 #> 5   1990 #> 6   1990"},{"path":"https://rodrodr.github.io/tenet/reference/bra.inaugural.html","id":null,"dir":"Reference","previous_headings":"","what":"Brazilian Presidents' Inaugural Speeches — bra.inaugural","title":"Brazilian Presidents' Inaugural Speeches — bra.inaugural","text":"dataset contains 37 Inaugural Speeches 1889 2023.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/bra.inaugural.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brazilian Presidents' Inaugural Speeches — bra.inaugural","text":"","code":"bra.inaugural"},{"path":"https://rodrodr.github.io/tenet/reference/bra.inaugural.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Brazilian Presidents' Inaugural Speeches — bra.inaugural","text":"quanteda corpus object following variables: doc_id character; Document ID text character; Text inaugural speech President character; Name President gave speech Legislature numeric; number legislature Date date; Date Speech Military logical; Military President Party character; Political Party President Interrupted logical; administration interrupted? Interrupt.Cause character; Cause interruption link_photo character; URL photos President","code":""},{"path":"https://rodrodr.github.io/tenet/reference/bra.inaugural.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Brazilian Presidents' Inaugural Speeches — bra.inaugural","text":"Presidencia.gov.br Bonfim (2005).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/bra.inaugural.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Brazilian Presidents' Inaugural Speeches — bra.inaugural","text":"","code":"# some operations on the corpus summary(bra.inaugural) #> Corpus consisting of 37 documents, showing 37 documents: #>  #>                                  Text Types Tokens Sentences Year #>         01. Deodoro da Fonseca (1889)   193    367         9 1889 #>           02. Floriano Peixoto (1891)   389    835        22 1891 #>         03. Prudente de Moraes (1894)   637   1438        26 1894 #>               04. Campos Sales (1898)  1416   4054       109 1898 #>            05. Rodrigues Alves (1902)   857   2112        55 1902 #>              06. Affonso Penna (1906)  1470   3952       104 1906 #>          07. Hermes da Fonseca (1910)  1138   2966        51 1910 #>             08. Wenceslau Brás (1914)  1525   4286       131 1914 #>            09. Epitácio Pessoa (1919)  1420   4094       113 1919 #>           10. Arthur Bernardes (1922)   319    586        13 1922 #>            11. Washington Luís (1926)   256    505        19 1926 #>             12. Getúlio Vargas (1930)   789   1754        44 1930 #>             13. Getúlio Vargas (1934)   592   1175        47 1934 #>             14. Getúlio Vargas (1937)  1488   3924       102 1937 #>        15. Eurico Gaspar Dutra (1946)   421   1310        25 1946 #>             16. Getúlio Vargas (1951)   604   1310        51 1951 #>       17. Juscelino Kubitschek (1956)   322    711        23 1956 #>              18. Jânio Quadros (1961)   386    737        25 1961 #>               19. João Goulart (1961)   461   1191        49 1961 #>             20. Castelo Branco (1964)   512   1151        37 1964 #>              21. Costa e Silva (1967)   639   1472        54 1967 #>   22. Emílio Garrastazu Médici (1969)   766   2276        85 1969 #>             23. Ernesto Geisel (1974)   379    715        17 1974 #>    24. João Batista Figueiredo (1979)   755   1755        82 1979 #>                25. José Sarney (1985)  1558   4476       261 1985 #>             26. Tancredo Neves (1985)  1198   3282       112 1985 #>    27. Fernando Collor de Melo (1990)  2076   6664       261 1990 #>              28. Itamar Franco (1992)   339    700        34 1992 #>  29. Fernando Henrique Cardoso (1995)  1297   3730       163 1995 #>  30. Fernando Henrique Cardoso (1999)  1112   2977       173 1999 #>  31. Luis Inácio Lula da Silva (2003)  1530   4380       147 2003 #>  32. Luis Inácio Lula da Silva (2007)  1440   4334       201 2007 #>             33. Dilma Rousseff (2011)  1343   4305       177 2011 #>             34. Dilma Rousseff (2015)  1582   5122       195 2015 #>               35. Michel Temer (2016)  1085   3183       138 2016 #>             36. Jair Bolsonaro (2019)   580   1298        60 2019 #>  37. Luis Inácio Lula da Silva (2023)  1213   3318       147 2023 #>                  President       Date Military    Party Interrupted #>         Deodoro da Fonseca 1889-11-16      Yes Military          No #>           Floriano Peixoto 1891-11-23      Yes Military          No #>         Prudente de Moraes 1894-11-15       No      PRF          No #>               Campos Sales 1898-11-15       No      PRP          No #>            Rodrigues Alves 1902-11-15       No      PRP          No #>              Affonso Penna 1906-11-15       No      PRM         Yes #>          Hermes da Fonseca 1910-11-15      Yes      PRC          No #>             Wenceslau Brás 1914-11-15       No      PRM         Yes #>            Epitácio Pessoa 1919-09-03       No      PRM          No #>           Arthur Bernardes 1922-11-16       No      PRM          No #>            Washington Luís 1926-11-16       No      PRP         Yes #>             Getúlio Vargas 1930-10-24       No No party          No #>             Getúlio Vargas 1934-07-21       No No party          No #>             Getúlio Vargas 1937-11-10       No No party         Yes #>        Eurico Gaspar Dutra 1946-01-31      Yes      PSD          No #>             Getúlio Vargas 1951-01-31       No      PTB         Yes #>       Juscelino Kubitschek 1956-01-31       No      PSD          No #>              Jânio Quadros 1961-01-31       No      PTN         Yes #>               João Goulart 1961-09-08       No      PTB         Yes #>             Castelo Branco 1964-04-15      Yes Military          No #>              Costa e Silva 1967-03-15      Yes Military          No #>   Emílio Garrastazu Médici 1969-10-30      Yes Military          No #>             Ernesto Geisel 1974-03-15      Yes Military          No #>    João Batista Figueiredo 1979-03-15      Yes Military          No #>                José Sarney 1985-03-15       No     PMDB          No #>             Tancredo Neves 1985-07-22       No     PMDB         Yes #>    Fernando Collor de Melo 1990-03-15       No      PRN         Yes #>              Itamar Franco 1992-10-02       No     PMDB          No #>  Fernando Henrique Cardoso 1995-01-01       No     PSDB          No #>  Fernando Henrique Cardoso 1999-01-01       No     PSDB          No #>  Luis Inácio Lula da Silva 2003-01-01       No       PT          No #>  Luis Inácio Lula da Silva 2007-01-01       No       PT          No #>             Dilma Rousseff 2011-01-01       No       PT          No #>             Dilma Rousseff 2015-01-01       No       PT         Yes #>               Michel Temer       <NA>       No     PMDB          No #>             Jair Bolsonaro 2019-01-01       No      PSL          No #>  Luis Inácio Lula da Silva 2023-01-01       No       PT        <NA> #>  Interrupt.Cause Elected                link_photo #>               No      No https://shorturl.at/bjUY0 #>               No      No https://shorturl.at/luzEG #>               No     Yes https://shorturl.at/bdgAR #>               No     Yes https://shorturl.at/buLQ5 #>               No     Yes https://shorturl.at/lwCN3 #>            Death     Yes https://shorturl.at/gwGX2 #>               No     Yes https://shorturl.at/bcoK2 #>            Death     Yes https://shorturl.at/gluJN #>               No      No https://shorturl.at/JU147 #>               No     Yes https://shorturl.at/wAHJZ #>             Coup     Yes https://shorturl.at/tRZ27 #>               No      No https://shorturl.at/antuC #>               No      No https://shorturl.at/antuC #>             Coup      No https://shorturl.at/antuC #>               No     Yes https://shorturl.at/fkoEH #>          Suicide     Yes https://shorturl.at/brGWX #>               No     Yes https://shorturl.at/nHP59 #>        Renounced     Yes https://shorturl.at/bDGLM #>             Coup      No https://shorturl.at/asIT4 #>               No      No https://shorturl.at/aoqsS #>               No      No https://shorturl.at/hrX14 #>               No      No https://shorturl.at/lmAHX #>               No      No https://shorturl.at/oszGT #>               No      No https://shorturl.at/bikOR #>               No      No https://shorturl.at/fqzG5 #>            Death      No https://shorturl.at/mAWX5 #>      Impeachment     Yes https://shorturl.at/agzWY #>               No      No https://shorturl.at/euM45 #>               No     Yes https://shorturl.at/ghNX8 #>               No     Yes https://shorturl.at/ghNX8 #>               No     Yes https://shorturl.at/dsAM3 #>               No     Yes https://shorturl.at/dsAM3 #>               No     Yes https://shorturl.at/lpvB6 #>      Impeachment     Yes https://shorturl.at/lpvB6 #>               No      No https://shorturl.at/pH489 #>               No     Yes https://shorturl.at/bsu56 #>             <NA>     Yes https://shorturl.at/ijkyY #>"},{"path":"https://rodrodr.github.io/tenet/reference/cis.corrupt.html","id":null,"dir":"Reference","previous_headings":"","what":"Political Corruption in Spain — cis.corrupt","title":"Political Corruption in Spain — cis.corrupt","text":"dataset contains transcription 7 focus groups political corruption Spain. study performed Centro de Investigaciones Sociológicas (CIS) number E2863 March, 2011.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/cis.corrupt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Political Corruption in Spain — cis.corrupt","text":"","code":"cis.corrupt"},{"path":"https://rodrodr.github.io/tenet/reference/cis.corrupt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Political Corruption in Spain — cis.corrupt","text":"data.frame object following variables: Persona character; person speaking. text character; Text containing intervention participant. Order integer; Order overall interventions. Tipo.Persona character; Tipe participant: Moderator, Female, Male. Estudio character; Study number: E2863. Grupo.Discusion integer; Number focus group. Ciudad character; Name city focus group took place. Fecha date; Date focus group. Grupo.Demografico character; Name demographic group: \"Housewives\", \"Businessmen\",\"University Students\", \"Public Servants\", \"Occupied - Young\", \"Workers\", \"Liberal Professionals\". Desc.Grupo character; Detailed description demographic group. Edad character; Age interval participants.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/cis.corrupt.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Political Corruption in Spain — cis.corrupt","text":"CIS (2011).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/cis.corrupt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Political Corruption in Spain — cis.corrupt","text":"","code":"# some operations on the data summary(cis.corrupt) #>    Persona              text               Order       Tipo.Persona       #>  Length:4445        Length:4445        Min.   :  1.0   Length:4445        #>  Class :character   Class :character   1st Qu.:159.0   Class :character   #>  Mode  :character   Mode  :character   Median :318.0   Mode  :character   #>                                        Mean   :335.6                      #>                                        3rd Qu.:495.0                      #>                                        Max.   :837.0                      #>    Estudio          Grupo.Discusion    Ciudad             Fecha           #>  Length:4445        Min.   :1.000   Length:4445        Length:4445        #>  Class :character   1st Qu.:2.000   Class :character   Class :character   #>  Mode  :character   Median :4.000   Mode  :character   Mode  :character   #>                     Mean   :3.842                                         #>                     3rd Qu.:6.000                                         #>                     Max.   :7.000                                         #>  Grupo.Demografico   Desc.Grupo            Edad           #>  Length:4445        Length:4445        Length:4445        #>  Class :character   Class :character   Class :character   #>  Mode  :character   Mode  :character   Mode  :character   #>                                                           #>                                                           #>                                                           head(cis.corrupt) #>   Persona #> 1     Mod #> 2      M1 #> 3     Mod #> 4      M1 #> 5     Mod #> 6      M1 #>                                                                                                                                                                                                                                                                                                                                                                                              text #> 1  Bueno, en primer lugar queria daros la bienvenida y agradeceros que os hayais animado a pasar aqui una tarde conmigo de trabajo, por decirlo. Os queria pedir, por favor, si no teneis ningun problema, permiso para grabar la sesion porque asi puedo estar mas tranquila, pendiente de la conversacion y no tener que estar tomando ninguna nota. Bueno, os voy a explicar un poco de que va #> 2                                                                                                                                                                                                                                                                                                         Perdona, es para preparar una entrevista de trabajo, sera un segundo. Esta sin volumen. #> 3                                                                                                                                                                                                                                                                                                                                                                               ?Te van a llamar? #> 4                                                                                                                                                                                                                                                                                                                                                                          Si, no salgo siquiera. #> 5                                                                                                                                                                                                                                                                                                                                                                        Bueno, lo que prefieras. #> 6                                                                                                                                                                                                                                                                                                                                                                  \"Si a las seis, seis y media\". #>   Order Tipo.Persona Estudio Grupo.Discusion   Ciudad      Fecha #> 1     1    Moderador   E2863               1 Valencia 2011-03-10 #> 2     2        Mujer   E2863               1 Valencia 2011-03-10 #> 3     3    Moderador   E2863               1 Valencia 2011-03-10 #> 4     4        Mujer   E2863               1 Valencia 2011-03-10 #> 5     5    Moderador   E2863               1 Valencia 2011-03-10 #> 6     6        Mujer   E2863               1 Valencia 2011-03-10 #>   Grupo.Demografico #> 1      Amas de casa #> 2      Amas de casa #> 3      Amas de casa #> 4      Amas de casa #> 5      Amas de casa #> 6      Amas de casa #>                                                                                                                               Desc.Grupo #> 1 Grupo de amas de casa, 50 años a 60 (compañeras de empleados y funcionarios con empleados bajo su responsabilidad, de técnicos medios) #> 2 Grupo de amas de casa, 50 años a 60 (compañeras de empleados y funcionarios con empleados bajo su responsabilidad, de técnicos medios) #> 3 Grupo de amas de casa, 50 años a 60 (compañeras de empleados y funcionarios con empleados bajo su responsabilidad, de técnicos medios) #> 4 Grupo de amas de casa, 50 años a 60 (compañeras de empleados y funcionarios con empleados bajo su responsabilidad, de técnicos medios) #> 5 Grupo de amas de casa, 50 años a 60 (compañeras de empleados y funcionarios con empleados bajo su responsabilidad, de técnicos medios) #> 6 Grupo de amas de casa, 50 años a 60 (compañeras de empleados y funcionarios con empleados bajo su responsabilidad, de técnicos medios) #>    Edad #> 1 50-60 #> 2 50-60 #> 3 50-60 #> 4 50-60 #> 5 50-60 #> 6 50-60"},{"path":"https://rodrodr.github.io/tenet/reference/colBright.html","id":null,"dir":"Reference","previous_headings":"","what":"Color Brightness for Labels — colBright","title":"Color Brightness for Labels — colBright","text":"Evaluates brightness background colors return light colors labels background dark dark colors background light.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/colBright.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Color Brightness for Labels — colBright","text":"","code":"colBright(colors,         limit=130,         bright=\"white\",         dark=\"black\")"},{"path":"https://rodrodr.github.io/tenet/reference/colBright.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Color Brightness for Labels — colBright","text":"colors Background colors employed plots. limit Luminosity threshold separate bright dark colors. default 130. bright label color returned background colors considered dark. default white. dark label color returned background colors considered bright. default black.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/colBright.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Color Brightness for Labels — colBright","text":"Calculates ratio frequency given term compared appearance whole corpus. function particularly useful selecting texts according themes issues. allows users select documents containing ideas interest.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/colBright.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Color Brightness for Labels — colBright","text":"function presents two possible values returned. default frequency ratio. ratio term high (much higher 1) cases documents concentrate occurence. zero texts matches 0 1 documents frequency average. option \"return.selected=TRUE\", function return values ratio limit established \"threshold\" argument. default last parameter return values 0, .e., texts term obsersed least .","code":""},{"path":"https://rodrodr.github.io/tenet/reference/colBright.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Color Brightness for Labels — colBright","text":"","code":"if (FALSE) { # Establish a set of both dark and light colors col <- c(\"white\",\"grey20\",\"black\",\"orange\",\"red3\",\"green\")  # Use the function to return label colors colBright(col)  # Change the default colors colBright(col, bright=\"yellow\", dark=\"blue\") }"},{"path":"https://rodrodr.github.io/tenet/reference/corNet.html","id":null,"dir":"Reference","previous_headings":"","what":"Sociogram of a Correlation Matrix — corNet","title":"Sociogram of a Correlation Matrix — corNet","text":"Generates network chart correlations among words corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corNet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sociogram of a Correlation Matrix — corNet","text":"","code":"corNet(cor.list,         link.col=c(\"red\",\"steelblue1\"),        link.alpha=0.7,        link.curvature=0.25,        node.col=\"purple\",        family=\"sans\",        layout=\"fr\")"},{"path":"https://rodrodr.github.io/tenet/reference/corNet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sociogram of a Correlation Matrix — corNet","text":"cor.list list containing edge list details vectors produces function corTerms. link.col color links/edges among words. default red (negative correlations) steelblue1 (positive ones). link.alpha opacity link colors. default 0.3. link.curvature curvature links/edges graph. default 0.25. node.col Indicates degree correlation used filter values returned. default \"purple\". family Font family used labeling values. default \"sans\". layout network layout graph. possible options : \"circle\",\"sphere\",\"nicely\",\"fr\",\"gem\",\"kk\",\"mds\",\"dh\",\"lgl\",\"sugiyama\". default \"fr\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corNet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sociogram of a Correlation Matrix — corNet","text":"function corNet generates network graph (sociogram) correlation among words corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corNet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sociogram of a Correlation Matrix — corNet","text":"ggplot2 chart.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corNet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sociogram of a Correlation Matrix — corNet","text":"","code":"if (FALSE) { # Create a corpus object cb <- bra.inaugural  # Generates a list of correlations ll <- corTerms(cb,                  lang = \"pt\",                  min.freq = 50,                  n.terms = 50,                  remove.wordlist = c(\"é\",                                 \"ser\",                                 \"fazer\",                                 \"cada\",                                 \"neste\"))  # Plots the sociogram corNet(ll) }"},{"path":"https://rodrodr.github.io/tenet/reference/corTerms.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlation Analysis of Words in a Corpus — corTerms","title":"Correlation Analysis of Words in a Corpus — corTerms","text":"Performs correlation analysis frequency words contained corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corTerms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlation Analysis of Words in a Corpus — corTerms","text":"","code":"corTerms(corpus,          min.freq = 20,         lang=\"es\",         method=\"spearman\",         r.lim=0,         n.terms=50,         remove.wordlist=NULL)"},{"path":"https://rodrodr.github.io/tenet/reference/corTerms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlation Analysis of Words in a Corpus — corTerms","text":"corpus quanteda corpus containing texts. min.freq minimum frequency included analysis. default 20. lang language removing stopwords. default Spanish: \"es\". method correlation method employed correlation. default \"spearman\", options \"pearson\", \"kendall\", \"yule\" (last one converts frequencies binary data calculating correlation). r.lim Indicates degree correlation used filter values returned. default 0. n.terms Indicates number terms returned function. default 50. remove.wordlist List words removed analysis alonside stopwords. default NULL.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corTerms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Correlation Analysis of Words in a Corpus — corTerms","text":"function corTerm calculates correlation coefficient frequency words contained corpus object. designed work corNet function creates sociogram links among words.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corTerms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correlation Analysis of Words in a Corpus — corTerms","text":"list containing two data.frame objects. first, edges, edge list three variables: term1, term2, value. second, vertices, indicates feature, frequency, number documents appears.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/corTerms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correlation Analysis of Words in a Corpus — corTerms","text":"","code":"# Create a corpus object cb <- bra.inaugural  # Generates a list of correlations ll <- corTerms( cb,                  lang = \"pt\",                  min.freq = 50,                  n.terms = 50,                  remove.wordlist = c(\"é\",                                 \"ser\",                                 \"fazer\",                                 \"cada\",                                 \"neste\"))"},{"path":"https://rodrodr.github.io/tenet/reference/countKeywords.html","id":null,"dir":"Reference","previous_headings":"","what":"Frequency of Dictionary Terms in a Corpus — countKeywords","title":"Frequency of Dictionary Terms in a Corpus — countKeywords","text":"Calculates absolute relative frequency dictionary terms given corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/countKeywords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frequency of Dictionary Terms in a Corpus — countKeywords","text":"","code":"countKeywords(corpus,                dic,                group.var=NULL,                rel.freq=FALSE,                case_insensitive=TRUE,               quietly=FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/countKeywords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frequency of Dictionary Terms in a Corpus — countKeywords","text":"corpus quanteda corpus containing texts. dic quanteda dictionary object containing terms searched. group.var variable corpus metadata decompose results. default NULL (groups considered without desaggregation). rel.freq Establishes whether function calculates relative frequency. default FALSE. case_insensitive Indicates search insensitive lower uppercase letters. default TRUE. quietly Logical. Indicates function hides progress bar . default FALSE.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/countKeywords.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Frequency of Dictionary Terms in a Corpus — countKeywords","text":"function countKeywords calculates number times term dictionary appears corpus. allows absolute relative frequencies. Grouping variables contained corpus metadata can also employed disaggregate result categories.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/countKeywords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frequency of Dictionary Terms in a Corpus — countKeywords","text":"data.frame object containing groups (group.var argument specified), categories dictionary, keywords composing category coding level, frequency.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/countKeywords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frequency of Dictionary Terms in a Corpus — countKeywords","text":"","code":"if (FALSE) { # Create a corpus object library(quanteda) cb <- corpus(spa.inaugural)  # use the dic.pol.es dictionary dic <- dic.pol.es  # Generates the frequencies d <- countKeywords(cb,                     dic)                     # Generates the relative frequencies  # by President d <- countKeywords(cb,                     dic,                    group.var=\"President\",                    rel.freq=TRUE) }"},{"path":"https://rodrodr.github.io/tenet/reference/dic.pol.es.html","id":null,"dir":"Reference","previous_headings":"","what":"dic.pol.es - Spanish Political Discourses Dictionary — dic.pol.es","title":"dic.pol.es - Spanish Political Discourses Dictionary — dic.pol.es","text":"dictionary contains nested (two-level) set codes analyzing Spanish inaugural speeches.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/dic.pol.es.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dic.pol.es - Spanish Political Discourses Dictionary — dic.pol.es","text":"","code":"dic.pol.es"},{"path":"https://rodrodr.github.io/tenet/reference/dic.pol.es.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"dic.pol.es - Spanish Political Discourses Dictionary — dic.pol.es","text":"quanteda dictionary object following levels: level1 character; Broad political issues. level2 character; Specific codes. keywords character; Terms employed search code/issue.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/dic.pol.es.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"dic.pol.es - Spanish Political Discourses Dictionary — dic.pol.es","text":"elaboration.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/dic.pol.es.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dic.pol.es - Spanish Political Discourses Dictionary — dic.pol.es","text":"","code":"# some operations on the corpus summary(dic.pol.es) #>                  Length Class       Mode #> actores          3      dictionary2 list #> postmaterialismo 3      dictionary2 list #> defensa          2      dictionary2 list #> discurso         3      dictionary2 list #> exterior         2      dictionary2 list #> fiscal           2      dictionary2 list #> instituciones    3      dictionary2 list #> social           2      dictionary2 list #> tecnologia       2      dictionary2 list #> territorial      3      dictionary2 list"},{"path":"https://rodrodr.github.io/tenet/reference/filterWords.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Words from a Corpus — filterWords","title":"Filter Words from a Corpus — filterWords","text":"function extracts words relative position corpus object based either keyword list dictionary.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Words from a Corpus — filterWords","text":"","code":"filterWords(corpus,             keywords,             rem.accent = FALSE,             rem.punct = TRUE,             case.insensitive = TRUE,             lang = \"es\",             fast = TRUE)"},{"path":"https://rodrodr.github.io/tenet/reference/filterWords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Words from a Corpus — filterWords","text":"corpus quanteda corpus object. keywords Keywords dictionary employed search terms texts. rem.accent Remove accents. default FALSE. rem.punct Remove punctuation. default TRUE. case.insensitive Search upper lowercase words. default TRUE. lang language removing stopwords. default Spanish: \"es\". fast Use fast algorithm tokenize texts. default TRUE (lower precision).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWords.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter Words from a Corpus — filterWords","text":"function searches terms using keyword list dictionary returns list words relative position text. results useful employed later Lexical Dispersion Plot.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Words from a Corpus — filterWords","text":"data.frame containing words retreived, relative position text grouping variable, existing.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Words from a Corpus — filterWords","text":"","code":"if (FALSE) { # Retrieve a corpus of text  tx <- quanteda::data_corpus_inaugural  # find the relative position of keywords filterWords(corpus=tx,              keywords=c(\"democ\",\"liber\",\"govern\"),             lang=\"en\") }"},{"path":"https://rodrodr.github.io/tenet/reference/filterWordsAttribute.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Words from a Corpus by Attribute — filterWordsAttribute","title":"Filter Words from a Corpus by Attribute — filterWordsAttribute","text":"function extracts relative position attribute associated metadata text corpus object.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWordsAttribute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Words from a Corpus by Attribute — filterWordsAttribute","text":"","code":"filterWordsAttribute(corpus,             docvar,             value,             aggr.by.var)"},{"path":"https://rodrodr.github.io/tenet/reference/filterWordsAttribute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Words from a Corpus by Attribute — filterWordsAttribute","text":"corpus quanteda corpus object. docvar Metadata variable associated texts quanteda corpus object. value List values contained metadata variable (docvar). aggr..var Establish grouping variable used creation new aggregated corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWordsAttribute.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter Words from a Corpus by Attribute — filterWordsAttribute","text":"function searches words based values metadata variable allows new aggregation data according another grouping variable. helps identify actors, institutions, attributes presented text highlight relative position aggregated perspective.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWordsAttribute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Words from a Corpus by Attribute — filterWordsAttribute","text":"data.frame containing words retreived, relative position text grouping variable new corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/filterWordsAttribute.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Words from a Corpus by Attribute — filterWordsAttribute","text":"","code":"if (FALSE) { # Retrieve a corpus of text  tx <- quanteda::data_corpus_inaugural  # find the relative position of keywords filterWordsAttribute(corpus=tx,                       docvar=\"President\",                       value=c(\"Nixon\",\"Bush\",                               \"Kennedy\",\"Roosevelt\"),                      aggr.by.var = \"Party\") }"},{"path":"https://rodrodr.github.io/tenet/reference/fixParagraph.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix sentences from texts extracted from PDF and other text documents. — fixParagraph","title":"Fix sentences from texts extracted from PDF and other text documents. — fixParagraph","text":"Remove line breaks, hyphenizations, interruptions paragraph flows.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/fixParagraph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix sentences from texts extracted from PDF and other text documents. — fixParagraph","text":"","code":"fixParagraph(text,               check.doubleline=FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/fixParagraph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix sentences from texts extracted from PDF and other text documents. — fixParagraph","text":"text character vector containing text processed. check.doubleline Replace values one newline character include also two newline characters. default FALSE (one).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/fixParagraph.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fix sentences from texts extracted from PDF and other text documents. — fixParagraph","text":"function fixes texts extracted documents formats convert row new line. cases, sentences paragraphs broken several parts. fragmentation hinders analysis texts organization paragraph sentence-based corpora. function also allows correction Latin texts without need remove accents diacritics.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/fixParagraph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix sentences from texts extracted from PDF and other text documents. — fixParagraph","text":"character vector corrected text.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/fixParagraph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fix sentences from texts extracted from PDF and other text documents. — fixParagraph","text":"","code":"if (FALSE) { # An example text from Lewis Mumford \"The Myth of the Maschine\": tx <- \"From Peking Man onward, some five hundred thousand years ago, caves have served as the womb and the tomb of human culture. All over the world, caves and grottoes became sacred places, reserved for ceremonials and for memorials of the dead. The paleolithic cave (top left) at La Magdeleine has two female figures at either side of the entrance and a horse in the foreground at the right, not visible here. The Temple of Siva at Elephanta, one of the many examples in India of temples and statues hollowed out of a stone mountain, repeats that ancient arrangement of symbols. But early man also appropriated caves for shelter, se- curity, and storage: witness (top right) this later Amerindian habitation within a cliff. (Top left) La Magdeleine (Tarn). From Sigfried Giedion, 'The Eternal Present.' Photograph by Achille Weider. (Top right) Gila National Monument. New Mexico. Courtesy of United States Department of the Interior, National Park Service Photo. (Bottom) Siva Temple, Elephanta, c. Eighth century. Cour- tesy of Museum of Fine Arts, Boston.\"  # Inspect the text format cat(tx)  # Apply the function tx <- fixParagraph(tx)  # Reinspect the text format cat(tx) }"},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree-shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny bindings for mywidget — forceClusTree-shiny","title":"Shiny bindings for mywidget — forceClusTree-shiny","text":"Output render functions using mywidget within Shiny applications interactive Rmd documents.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree-shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny bindings for mywidget — forceClusTree-shiny","text":"","code":"forceClusTreeOutput(outputId, width = \"100%\", height = \"800px\")  renderforceClusTree(expr, env = parent.frame(), quoted = FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree-shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny bindings for mywidget — forceClusTree-shiny","text":"outputId output variable read width, height Must valid CSS unit (like '100%', '400px', 'auto') number, coerced string 'px' appended. expr expression generates mywidget env environment evaluate expr. quoted expr quoted expression (quote())? useful want save expression variable.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Force Directed Hierarchical Cluster Tree Network — forceClusTree","title":"Force Directed Hierarchical Cluster Tree Network — forceClusTree","text":"Generates Force Directed Hierarchical Cluster Tree Network Graph corpus objects.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Force Directed Hierarchical Cluster Tree Network — forceClusTree","text":"","code":"forceClusTree(corpus,                remove_punct=TRUE,               lang = \"es\",               palette = c(\"#DD8D29\",\"#E2D200\",\"#46ACC8\",\"#E58601\",\"#B40F20\"),               groupvar = NULL,               width=\"100%\",               height=580,               link.width=2,               maxRadius=30,               BodyStrength=-10,               include.text=FALSE,               img.docvar=NULL,               clust.method=\"euclidean\",               weight.scheme=\"logcount\",               elementId=\"chartdivclus\")"},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Force Directed Hierarchical Cluster Tree Network — forceClusTree","text":"corpus quanteda corpus object. remove_punct Remove punctuation. default TRUE. lang language removing stopwords. default Spanish: \"es\". palette color palette employed. groupvar Metadata variable associated texts quanteda corpus object indicating groups aggregated categories. width width html panel. default 100%. height height html panel pixels. default 580. link.width width links connecting nodes network. default 2. maxRadius maximum radius nodes network. default 100. BodyStrength attraction force nodes network.  default -10. include.text Logical. Indicates function include text tooltip. used small texts. Large texts collapse visualization. default FALSE. img.docvar Indicates name variable corpus metadata containing url links images displayed tooltip. default NULL. clust.method Indicates method calculating text distance. options : \"euclidean\" (default), \"manhattan\", \"maximum\", \"canberra\", \"minkowski\". weight.scheme Indicates method calculating weights pondering significance words text. options : \"logcount\" (default), \"count\", \"prop\", \"propmax\", \"boolean\", \"augmented\", \"logave\". See quateda's dfm_weight information scheme calculated. elementId Name div element employed contain graph. useful use type graph multiple times markdown page, instance. default \"chartdivclus\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Force Directed Hierarchical Cluster Tree Network — forceClusTree","text":"function generates Force Directed Hierarchical Cluster Tree Network Graph quanteda corpuses. calculates similarity among texts organizes according tree structure. interactive traits chart allow users explore relationships depth.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Force Directed Hierarchical Cluster Tree Network — forceClusTree","text":"chart representing similarity texts html source code generated.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceClusTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Force Directed Hierarchical Cluster Tree Network — forceClusTree","text":"","code":"if (FALSE) { # Retrieve a corpus of text  tx <- quanteda::data_corpus_inaugural  # Create the graph for the inaugural discourses forceClusTree(tx, lang=\"en\", maxRadius = 50) }"},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree-shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny bindings for mywidget — forceDirectedTree-shiny","title":"Shiny bindings for mywidget — forceDirectedTree-shiny","text":"Output render functions using mywidget within Shiny applications interactive Rmd documents.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree-shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny bindings for mywidget — forceDirectedTree-shiny","text":"","code":"forceDirectedTreeOutput(outputId, width = \"100%\", height = \"800px\")  renderforceDirectedTree(expr, env = parent.frame(), quoted = FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree-shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny bindings for mywidget — forceDirectedTree-shiny","text":"outputId output variable read width, height Must valid CSS unit (like '100%', '400px', 'auto') number, coerced string 'px' appended. expr expression generates mywidget env environment evaluate expr. quoted expr quoted expression (quote())? useful want save expression variable.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Force Directed Tree Chart — forceDirectedTree","title":"Force Directed Tree Chart — forceDirectedTree","text":"Creates Force Directed Tree Chart visualizing hierarchical data.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Force Directed Tree Chart — forceDirectedTree","text":"","code":"forceDirectedTree(data,                   value_col=\"value\",                   attraction=-5,                    palette=c(\"#DD8D29\",\"#E2D200\",\"#46ACC8\",\"#E58601\",\"#B40F20\"),                    col.n=9,                    show.link=TRUE,                    height=800,                   width=\"100%\",                   max.radius=5,                   elementId=\"chartdiv\",                   tooltip.text=\"{name}: {value}\")"},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Force Directed Tree Chart — forceDirectedTree","text":"data hierarchical data.frame converted json tree. value_col name variable containing frequency value represented. default \"value\". attraction intensity attraction among nodes. default -5. palette color palette used represent nodes. default NULL (default \"Dark2\" RColorBrewer). col.n number colors represent. default 9. show.link Logical. Indicates links connecting nodes made visible. default TRUE. height height html panel pixels. default 800. width width html panel pixels percent. default 100%. max.radius maximum radius nodes percentage. default 5. elementId Name div element employed contain graph. useful use type graph multiple times markdown page, instance. default \"chartdiv\". tooltip.text option allows users customize text html code displayed tooltip chart. default \"name: value\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Force Directed Tree Chart — forceDirectedTree","text":"function generates Force Directed Tree Graph. allows users explore hierarchical data three levels.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Force Directed Tree Chart — forceDirectedTree","text":"Force Directed Tree chart html source code generated.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/forceDirectedTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Force Directed Tree Chart — forceDirectedTree","text":"","code":"if (FALSE) { # Create a test dataset dt <- data.frame(           Characters=c(\"Joao Grilo\",\"Chico\"),            Word.Type= c(\"Verb\",\"Noun\"),            Word=c(\"sing\",\"harmonica\"),            Frequency=c(2,3))            # Create the chart forceDirectedTree(dt, value_col=\"Frequency\") }"},{"path":"https://rodrodr.github.io/tenet/reference/matchCodes.html","id":null,"dir":"Reference","previous_headings":"","what":"Cooccurrence of Dictionary Terms in a Corpus — matchCodes","title":"Cooccurrence of Dictionary Terms in a Corpus — matchCodes","text":"Calculates cooccurrence dictionary terms given corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/matchCodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cooccurrence of Dictionary Terms in a Corpus — matchCodes","text":"","code":"matchCodes(corpus,                dic,               level=1,               remove.self=TRUE,               quietly=FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/matchCodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cooccurrence of Dictionary Terms in a Corpus — matchCodes","text":"corpus quanteda corpus object. dic Quanteda dictionary employed analysis. level level dictionary take account aggregation co-ocurrences. default 1 (top level abstraction). remove.self Logical. Indicates function remove co-ocurrences theme . default TRUE. quietly Logical. Indicates function hides progress bar . default FALSE.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/matchCodes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cooccurrence of Dictionary Terms in a Corpus — matchCodes","text":"function matchCodes calculates number times pair dictionary terms co-occur corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/matchCodes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cooccurrence of Dictionary Terms in a Corpus — matchCodes","text":"data.frame object containing three variables: term1, term2, value.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/matchCodes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cooccurrence of Dictionary Terms in a Corpus — matchCodes","text":"","code":"# Create a corpus object library(quanteda) #> Package version: 4.0.2 #> Unicode version: 14.0 #> ICU version: 70.1 #> Parallel computing: disabled #> See https://quanteda.io for tutorials and examples. cb <- corpus(spa.inaugural)  # use the dic.pol.es dictionary dic <- dic.pol.es  # Generates the results d <- matchCodes(cb, dic) #>    |                                                           |                                                  |   0%   |                                                           |=====                                             |  10%   |                                                           |==========                                        |  20%   |                                                           |===============                                   |  30%   |                                                           |====================                              |  40%   |                                                           |=========================                         |  50%   |                                                           |==============================                    |  60%   |                                                           |===================================               |  70%   |                                                           |========================================          |  80%   |                                                           |=============================================     |  90%   |                                                           |==================================================| 100%"},{"path":"https://rodrodr.github.io/tenet/reference/pal.html","id":null,"dir":"Reference","previous_headings":"","what":"Data Visualization Color Palettes — pal","title":"Data Visualization Color Palettes — pal","text":"list contains 222 color palettes classified type data. name repreents type: cat - categorical, div - divergent, seq - sequential; source R package, name palette number hues colors original palette.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/pal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data Visualization Color Palettes — pal","text":"","code":"pal"},{"path":"https://rodrodr.github.io/tenet/reference/pal.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data Visualization Color Palettes — pal","text":"object class list length 222.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/pcaScatter.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualization of Principal Component and Correspondence Analysis — pcaScatter","title":"Visualization of Principal Component and Correspondence Analysis — pcaScatter","text":"Performs Principal Component Correspondence Analysis text corpus plots results interactive scatter plot.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/pcaScatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualization of Principal Component and Correspondence Analysis — pcaScatter","text":"","code":"pcaScatter(corpus,             lang=\"es\",            min.freq = 100,            n.clusters = 4,            interactive = TRUE,            type = \"pca\",            title = \"Title\",            caption = \"Source: Own elaboration.\",            alpha = 0.5,            palette = c(\"#DD8D29\",\"#E2D200\",\"#46ACC8\",\"#E58601\",\"#B40F20\"))"},{"path":"https://rodrodr.github.io/tenet/reference/pcaScatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualization of Principal Component and Correspondence Analysis — pcaScatter","text":"corpus quanteda corpus containing texts. lang language removing stopwords. default Spanish: \"es\". min.freq minimum frequency included analysis. default 100. n.clusters number clusters divide results groups. default 4. interactive Logical. Indicates whether chart interactive ggplot2 object returned. default TRUE. type Indicates whether analysis PCA (type=\"pca\") Correspondence Analysis (type=\"ca\"). default \"pca\". title title graph. default \"Title\". caption caption graph. default \"Source: elaboration.\". alpha opacity colors. default 0.5 (50 percent opaque). palette One palettes included listPalettes function tenet. default NULL (Dark2 RColorBrewer).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/pcaScatter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Visualization of Principal Component and Correspondence Analysis — pcaScatter","text":"function pcaScatter allows users perform two dimension reduction analysis text data: Principal Component Analysis Correspondence Analysis. also applies hierarchical cluster algorithm results separate terms groups based similarity.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/pcaScatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualization of Principal Component and Correspondence Analysis — pcaScatter","text":"results either interactive graph ggplot2 object edited user.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/pcaScatter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualization of Principal Component and Correspondence Analysis — pcaScatter","text":"","code":"if (FALSE) {  # Create a corpus object library(quanteda) cp <- corpus(spa.inaugural)  # Generates a PCA using pcaScatter pcaScatter(cp,             title = \"Disc. Inauguración (1979-2019)\",             min.freq = 10)             # Now, performs a Correspondence Analysis pcaScatter(cp,             type=\"ca\",            title = \"Disc. Inauguración (1979-2019)\",             min.freq = 10) }"},{"path":"https://rodrodr.github.io/tenet/reference/plotChord-shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny bindings for mywidget — plotChord-shiny","title":"Shiny bindings for mywidget — plotChord-shiny","text":"Output render functions using mywidget within Shiny applications interactive Rmd documents.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotChord-shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny bindings for mywidget — plotChord-shiny","text":"","code":"plotChordOutput(outputId, width = \"100%\", height = \"400px\")  renderplotChord(expr, env = parent.frame(), quoted = FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/plotChord-shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny bindings for mywidget — plotChord-shiny","text":"outputId output variable read width, height Must valid CSS unit (like '100%', '400px', 'auto') number, coerced string 'px' appended. expr expression generates mywidget env environment evaluate expr. quoted expr quoted expression (quote())? useful want save expression variable.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotChord.html","id":null,"dir":"Reference","previous_headings":"","what":"Co-ocurrence Chord Diagram for Dictionary Codes and Themes — plotChord","title":"Co-ocurrence Chord Diagram for Dictionary Codes and Themes — plotChord","text":"Generates Chord Diagram Co-Ocurrence Dictionary Themes Corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotChord.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Co-ocurrence Chord Diagram for Dictionary Codes and Themes — plotChord","text":"","code":"plotChord(data,            from=\"from\",            to=\"to\",            value=\"value\",            font.size=12,            node.width=5,            opacity=0.05,            radius.percent=70,            height=600,            elementId=\"chordtheme\")"},{"path":"https://rodrodr.github.io/tenet/reference/plotChord.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Co-ocurrence Chord Diagram for Dictionary Codes and Themes — plotChord","text":"data data.frame three columns: origin, destination, value. name variable containing information group, origin aggregate measure. default \"\". name variable containing information detail category, destination attribute. default \"\". value name variable containing frequency value relationship given origin destination group attribute. default \"value\". font.size size font pixels. default 12. node.width width (thickness) node bar. default 5. opacity opacity links hovered. default 0.05 (5 percent opacity). radius.percent Percentage height occupied radius diagram. default 70. height height html panel pixels. default 580. elementId Name div element employed contain graph. useful use type graph multiple times markdown page, instance. default \"chordtheme\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotChord.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Co-ocurrence Chord Diagram for Dictionary Codes and Themes — plotChord","text":"function generates interactive Chord Diagram. allows users perform thematic analysis categorical hierarchical data analysis intuitively.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotChord.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Co-ocurrence Chord Diagram for Dictionary Codes and Themes — plotChord","text":"chart representing similarity texts html source code generated.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotChord.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Co-ocurrence Chord Diagram for Dictionary Codes and Themes — plotChord","text":"","code":"if (FALSE) { # Retrieve a corpus of text  cp <- quanteda::corpus(spa.inaugural)  # Loads the dictionary for Spanish Speeches dic <- dic.pol.es  # Generate the data to be employed d <- matchCodes(cp, dic)  # Create the graph for the inaugural discourses plotChord(d, from=\"term1\", to=\"term2\", value=\"value\") }"},{"path":"https://rodrodr.github.io/tenet/reference/plotGrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Proportional Symbol Grid Plot — plotGrid","title":"Proportional Symbol Grid Plot — plotGrid","text":"Creates grid proportional symbols representing tabular data.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotGrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Proportional Symbol Grid Plot — plotGrid","text":"","code":"plotGrid(data,          x=NULL,          y=NULL,          size=NULL,          color=NULL,          tooltip=NULL,          palette=c(\"#E41A1C\",                   \"#377EB8\",                   \"#4DAF4A\",                   \"#984EA3\",                   \"#FF7F00\",                   \"#FFFF33\",                   \"#A65628\",                   \"#F781BF\",                   \"#999999\"),          grid.color=\"grey90\",         interactive=TRUE,          family=\"Helvetica\",          x.axis.angle=90,          standardize=FALSE,          avg.mark=TRUE,          axis=\"y\",          alpha=TRUE,          width_svg = 9,          height_svg = 6,          leg.size=\"Size\",         leg.color=\"Dimension\",          point.shape=\"circle\")"},{"path":"https://rodrodr.github.io/tenet/reference/plotGrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Proportional Symbol Grid Plot — plotGrid","text":"data data frame containing two categorical variables shared frequencies. x character string specifying name column data used x-axis. y character string specifying name column data used y-axis. size character string specifying name column data used size symbols. color character string specifying name column data used color symbols. tooltip character string specifying name column data used tooltip. palette vector colors. default vector colors Set1 palette RColorBrewer package. grid.color character string specifying color grid. default \"grey90\". interactive logical value. TRUE, plot interactive. default TRUE. family character string specifying font family. default \"Helvetica\". x.axis.angle numeric value specifying angle x-axis labels. default 90. standardize logical value. TRUE, data standardized. default FALSE. avg.mark logical value. TRUE, average represented plot. default TRUE. axis character string specifying axis used calculation average. default \"y\". alpha logical value. TRUE, transparency bubbles proportional size. default TRUE. width_svg numeric value specifying width svg. default 9. height_svg numeric value specifying height svg. default 6. leg.size character string specifying title legend size. default \"Size\". leg.color character string specifying title legend color. default \"Dimension\". point.shape character string specifying shape points. possible values \"circle\",\"square\",\"triangle\",\"diamond\". default \"circle\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotGrid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Proportional Symbol Grid Plot — plotGrid","text":"function creates proportional symbol grid representing tabular data.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotGrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Proportional Symbol Grid Plot — plotGrid","text":"result ggplot2 chart ggiraph object (interactive true).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotGrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Proportional Symbol Grid Plot — plotGrid","text":"","code":"if (FALSE) { # Create a corpus with the inaugural speeches # Count the keywords library(quanteda) cp <- corpus(spa.inaugural)  xz <- countKeywords(cp,                      dic.pol.es,                      rel.freq = T,                      group.var = \"President\",                     quietly = TRUE)  # Aggregates the frecuencies by group # contained in the dictionary xx <- aggregate(list(frequency=xz$frequency),                  by=list(groups=xz$groups,                         level1=xz$level1,                         level2=xz$level2),                  sum, na.rm=T)  # Remove the zeros xx <- xx[xx$frequency>0,]  # Sort values by level1 and level2 xx <- xx[order(xx$level1, xx$level2),] xx$level2 <- factor(xx$level2, levels=unique(xx$level2))  # Create the non-standardized plot plotGrid(xx,           x=\"groups\",           y=\"level2\",           size=\"frequency\",          palette=pal$cat.awtools.bpalette.16,          color=\"level1\",          alpha=FALSE,           interactive=FALSE)  # Create the standardized plot plotGrid(xx,           x=\"groups\",           y=\"level2\",           size=\"frequency\",          palette=pal$cat.awtools.bpalette.16,          color=\"level1\",           standardize = TRUE,          interactive=TRUE)  }"},{"path":"https://rodrodr.github.io/tenet/reference/plotKeyness.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify salient keywords in reference texts. — plotKeyness","title":"Identify salient keywords in reference texts. — plotKeyness","text":"Creates plot identifying salient words reference text compared texts corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotKeyness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify salient keywords in reference texts. — plotKeyness","text":"","code":"plotKeyness(corpus,             group.var=NULL,             ref.cat,             p.value=0.01,             type=\"chi2\",             palette=c(\"red3\",\"goldenrod1\",\"dodgerblue3\"),             remove.punct=TRUE,             remove.number=TRUE,             remove.stopwords=TRUE,             use.stem=FALSE,             use.bigrams=FALSE,             label.dots=TRUE,             gray.area=0,             exclude.zeros=FALSE,             lang=\"es\",             title=\"Chi-Square vs. Log Frequency\",             title.text.size=14,             interactive=TRUE,             return.data=FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/plotKeyness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify salient keywords in reference texts. — plotKeyness","text":"corpus quanteda corpus object texts analyze. group.var character vector name grouping variable corpus (case corpus already grouped). ref.cat character string name reference category (one values grouping variable). p.value numeric value significance level chi-square test. default 0.01 (99% confidence). type character string type test use. Options \"chi2\" chi-square test, \"lr\" likelyhood ratio, \"log\" log-odds ratio chi2 results. default \"chi2\" palette character vector colors use plot. first color reference category, second categories, third gray area. default colors \"red3\",\"goldenrod1\", \"dodgerblue3\". remove.punct logical value indicating punctuation marks removed texts. default TRUE. remove.number logical value indicating numbers removed texts. default TRUE. remove.stopwords logical value indicating stopwords removed texts. default TRUE. use.stem logical value indicating texts stemmed. default FALSE. use.bigrams logical value indicating bigrams used analysis. default FALSE. label.dots logical value indicating words labeled plot. default TRUE. gray.area numeric value indicating value establishing bandwidth gray area plot. default 0 (gray area). exclude.zeros logical value indicating words zero frequency reference category excluded analysis. default FALSE. lang character string language texts. default \"es\" (Spanish). title character string title plot. default \"Chi-Square vs. Log Frequency\". title.text.size numeric value size title text. default 14. interactive logical value indicating plot interactive. default TRUE. return.data logical value indicating data used create plot returned. default FALSE.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotKeyness.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify salient keywords in reference texts. — plotKeyness","text":"function employs function textstat.keyness quanteda packages calculate salience words reference text compared others plot log frequency term corpus scaled 0-1 interval. Therefore, distant zero axes, salient term reference text. Terms zero particularly employed reference text zero absent greater degree prevalence compared texts corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotKeyness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify salient keywords in reference texts. — plotKeyness","text":"ggplot2 compatible scatter plot representing scaled log frequency term X-axis selected statistics Y-axis data.frame object containing statistics.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotKeyness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify salient keywords in reference texts. — plotKeyness","text":"","code":"if (FALSE) {  # Selects the session no. 124 of the Spanish parliament # discussing the law againgst sexual violence. spa <- spa.sessions[spa.sessions$session.number==124,]  # Aggregate Spanish parliamentary speeches # by party re <- aggregate(list(text=spa$speech.text),                  by=list(rep.party=spa$rep.party),                 FUN=paste,                  collapse=\"\\n\")  # Create a corpus object with the speeches cp <- corpus(re)  # Group the corpus by party ci <- corpus_group(cp, groups = rep.party)  # Plot the keyness (log-odds ratio) of the words  # in the speeches plotKeyness(corpus = ci,             type = \"log\",              ref.cat = \"Podemos\",              title = \"\")  }"},{"path":"https://rodrodr.github.io/tenet/reference/plotLexDiv.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexical Dispersion Plot — plotLexDiv","title":"Lexical Dispersion Plot — plotLexDiv","text":"function creates lexical dispersion plot corpus objects based keywords dictionaries.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLexDiv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexical Dispersion Plot — plotLexDiv","text":"","code":"plotLexDiv(corpus,            keywords,            docvar=NULL,                     value=NULL,            aggr.by.var=NULL,            rem.accent = TRUE,            rem.punct = TRUE,            case.insensitive = TRUE,            lang = \"es\",             title=\"Lexical Dispersion Plot\",             caption=\"Own elaboration.\",            subtitle=\"Keywords\",            legend.title=\"Group\",            legend.rows=1,            palette=c(\"#DD8D29\",\"#E2D200\",\"#46ACC8\",\"#E58601\",\"#B40F20\"),            custom.color=\"black\",            panel.bg.fill=\"grey98\",            hline.color=\"white\",            hline.width=0.5,            na.rm=FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/plotLexDiv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexical Dispersion Plot — plotLexDiv","text":"corpus quanteda corpus object. keywords Keywords dictionary employed search terms texts. docvar Metadata variable associated texts quanteda corpus object. value List values contained metadata variable (docvar). aggr..var Establish grouping variable used creation new aggregated corpus. rem.accent Remove accents. default TRUE. rem.punct Remove punctuation. default TRUE. case.insensitive Search upper lowercase words. default TRUE. lang language removing stopwords. default Spanish: \"es\". title title graph. default ist \"Lexical Dispersion Plot\". caption caption, note source graph. default \"elaboration\". subtitle subtitle graph. default \"Keywords\". legend.title title legend. default \"Group\". legend.rows number rows organizing groups legend. default 1. palette list color names hexadecimal codes represent groups. custom.color custom color used groups dictionary entries defined. default \"black\". panel.bg.fill background color text panels. default color \"grey98\". hline.color Horizontal line color. default \"white\". hline.width Horizontal line width. default 0.5. na.rm Logical. Removes texts contain keywords categories indicated. default FAlSE.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLexDiv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lexical Dispersion Plot — plotLexDiv","text":"function generates Lexical Dispersion Plot keywords, dictionaries metadata variables. represents position selected keywords, dictionary categories, metadata values text forming corpus object.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLexDiv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lexical Dispersion Plot — plotLexDiv","text":"chart representing dispersion terms concepts.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLexDiv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lexical Dispersion Plot — plotLexDiv","text":"","code":"if (FALSE) { # Retrieve a corpus of text  tx <- quanteda::data_corpus_inaugural  # find the relative position of keywords plotLexDiv(tx, keywords = c(\"democ\",\"liber\",\"freedom\"))  # creates a dictionary dic <- dictionary(list(                 Goverment=c(\"govern\",                             \"executive\",                             \"policy\"),                 Nation=c(\"nation\",                          \"homeland\",                          \"patriot\"),                 Democracy=c(\"democ\",                             \"freedom\",                             \"liberty\",                             \"rights\")                 ))  # Creates the graph                 plotLexDiv(tx,             keywords = dic)  # Aggregate the corpus according to party plotLexDiv(tx,             docvar=\"President\",             value=c(\"Nixon\",\"Bush\",\"Kennedy\",\"Roosevelt\"),             aggr.by.var = \"Party\") }"},{"path":"https://rodrodr.github.io/tenet/reference/plotLogOddsRatio.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Weighted Log Odds Ratio vs. Log Frequency Plot — plotLogOddsRatio","title":"Generate a Weighted Log Odds Ratio vs. Log Frequency Plot — plotLogOddsRatio","text":"plotLogOddsRatio function generates weighted log odds ratio vs. log frequency plot visualize relationship log odds ratios log frequencies tokens text corpus. function uses quanteda package text processing ggplot2 plotting. particularly useful analyzing significance token frequencies different categories documents within corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLogOddsRatio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Weighted Log Odds Ratio vs. Log Frequency Plot — plotLogOddsRatio","text":"","code":"plotLogOddsRatio(     corpus,     ref.cat,     comp.cat = NULL,     palette = c(\"red3\", \"goldenrod1\", \"dodgerblue3\"),     remove.punct = TRUE,     remove.number = TRUE,     remove.stopwords = TRUE,     use.stem = FALSE,     use.bigrams = FALSE,     label.dots = TRUE,     gray.area = 0,     exclude.zeros = FALSE,     lang = \"es\",     title = \"Weighted log odds ratio vs. Log Frequency\",     title.text.size = 14,     interactive = TRUE,     return.data = FALSE   )"},{"path":"https://rodrodr.github.io/tenet/reference/plotLogOddsRatio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Weighted Log Odds Ratio vs. Log Frequency Plot — plotLogOddsRatio","text":"corpus text corpus. ref.cat category document ID used reference category log odds ratio calculations. comp.cat vector category document IDs comparison (default: NULL). palette vector color codes specifying node colors (default: palette three colors). remove.punct logical value indicating whether remove punctuation tokens (default: TRUE). remove.number logical value indicating whether remove numbers tokens (default: TRUE). remove.stopwords logical value indicating whether remove stopwords tokens (default: TRUE). use.stem logical value indicating whether apply stemming tokens (default: FALSE). use.bigrams logical value indicating whether consider bigrams tokenization (default: FALSE). label.dots logical value indicating whether label data points token names (default: TRUE). gray.area numeric value specifying threshold gray area log odds ratio (default: 0). exclude.zeros logical value indicating whether exclude tokens zero frequency (default: FALSE). lang character specifying language text processing (default: \"es\" Spanish). title character specifying plot title (default: \"Weighted log odds ratio vs. Log Frequency\"). title.text.size integer specifying size plot title text (default: 14). interactive logical value indicating whether generate interactive plot (default: TRUE). return.data logical value indicating whether return data used plotting (default: FALSE).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLogOddsRatio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a Weighted Log Odds Ratio vs. Log Frequency Plot — plotLogOddsRatio","text":"plotLogOddsRatio function tokenizes text corpus, processes tokens based specified options (e.g., removing punctuation, stopwords, stemming), calculates log odds ratios, plots log odds ratios log frequencies. Tokens colored based log odds ratios, gray area can specified highlight significant tokens. plot can interactive, allowing tooltips data exploration.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLogOddsRatio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Weighted Log Odds Ratio vs. Log Frequency Plot — plotLogOddsRatio","text":"function returns either ggiraph interactive plot (interactive TRUE) ggplot2 plot (interactive FALSE). return.data TRUE, returns data frame containing plotted data.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotLogOddsRatio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a Weighted Log Odds Ratio vs. Log Frequency Plot — plotLogOddsRatio","text":"","code":"if (FALSE) {     # Example usage:     # Load required libraries     library(quanteda)     library(tenet)          # Creates a corpus of inaugural speeches     cp <- corpus(spa.inaugural)      # Group documents by President     ci <- corpus_group(cp, groups = President)      # Creates the plot     plotLogOddsRatio( corpus = ci,                        ref.cat = \"Zapatero\")                   }"},{"path":"https://rodrodr.github.io/tenet/reference/plotNetCentrality.html","id":null,"dir":"Reference","previous_headings":"","what":"Network Centrality Plot — plotNetCentrality","title":"Network Centrality Plot — plotNetCentrality","text":"Creates bar plot key network centrality measures.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotNetCentrality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Network Centrality Plot — plotNetCentrality","text":"","code":"plotNetCentrality(g,                    title=\"Network Centrality Measures\",                    subtitle=\"Ranking of nodes according to centrality.\",                   caption=\"Source: Own elaboration.\",                   palette=c(\"#1B9E77\",                              \"#D95F02\",                              \"#7570B3\",                              \"#E7298A\",                              \"#66A61E\",                              \"#E6AB02\",                              \"#A6761D\",                              \"#666666\"),                    methods=c(\"degree\",                             \"authority\",                             \"page_rank\",                             \"eigenvector\",                             \"betweenness\",                             \"closeness\",                             \"hub\"),                   topn=20,                   ties.method=\"min\")"},{"path":"https://rodrodr.github.io/tenet/reference/plotNetCentrality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Network Centrality Plot — plotNetCentrality","text":"g igraph object. title character string. title chart. default \"Network Centrality Measures\". subtitle character string. subtitle chart. default \"Ranking nodes according centrality.\". caption character string. caption chart. default \"Source: elaboration.\". palette character vector. color palette used chart. methods character vector. network centrality measures used chart. default c(\"degree\", \"authority\", \"page_rank\", \"eigenvector\", \"betweenness\", \"closeness\", \"hub\"). topn integer. number top nodes displayed chart. default 20. ties.method character string. method break ties ranking. default \"min\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotNetCentrality.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Network Centrality Plot — plotNetCentrality","text":"function corNet generates network graph (sociogram) correlation among words corpus. default centrality measures : degree, authority, page rank, eigenvector, betweenness, closeness hub.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotNetCentrality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Network Centrality Plot — plotNetCentrality","text":"ggplot2 chart.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotNetCentrality.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Network Centrality Plot — plotNetCentrality","text":"","code":"if (FALSE) {  # Create a random network graph library(igraph) g <- sample_gnp(100, 1/100)  # Plot the network centrality measures plotNetCentrality(g)  }"},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey-shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny bindings for mywidget — plotSankey-shiny","title":"Shiny bindings for mywidget — plotSankey-shiny","text":"Output render functions using mywidget within Shiny applications interactive Rmd documents.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey-shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny bindings for mywidget — plotSankey-shiny","text":"","code":"plotSankeyOutput(outputId, width = \"100%\", height = \"600px\")  renderplotSankey(expr, env = parent.frame(), quoted = FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey-shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny bindings for mywidget — plotSankey-shiny","text":"outputId output variable read width, height Must valid CSS unit (like '100%', '400px', 'auto') number, coerced string 'px' appended. expr expression generates mywidget env environment evaluate expr. quoted expr quoted expression (quote())? useful want save expression variable.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey.html","id":null,"dir":"Reference","previous_headings":"","what":"Sankey Diagram — plotSankey","title":"Sankey Diagram — plotSankey","text":"Creates Sankey Diagram two-level data.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sankey Diagram — plotSankey","text":"","code":"plotSankey(data,             from=\"from\",             to=\"to\",             value=\"value\",            font.size=12,             opacity=0.05,             paddingRight=150,             elementId=\"sankeydiv\",             height=600)"},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sankey Diagram — plotSankey","text":"data data.frame three columns: origin, destination, value. name variable containing information group, origin aggregate measure. default \"\". name variable containing information detail category, destination attribute. default \"\". value name variable containing frequency value relationship given origin destination group attribute. default \"value\". font.size size label font pixels. default 12. opacity opacity links hovered. default 0.05 (5 percent opacity). paddingRight size margin right side chart labels. default 150 pixels. elementId Name div element employed contain graph. useful use type graph multiple times markdown page, instance. default \"sankeydiv\". height height html panel pixels. default 600.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sankey Diagram — plotSankey","text":"function generates interactive Sankey Diagram representing hierarchical data. allows users explore textual data, codings themes intuitively.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sankey Diagram — plotSankey","text":"Sankey diagram html source code generated.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSankey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sankey Diagram — plotSankey","text":"","code":"if (FALSE) { # Create a test dataset cp <- corpus(spa.inaugural)  dic <- dic.pol.es  xx <- countKeywords(cp, dic.pol.es, rel.freq = F, group.var = \"President\")  xx <- aggregate(list(frequency=xx$frequency),                  by=list(groups=xx$groups,                          level1=xx$level1,                         level2=xx$level2),                  sum, na.rm=T)            # Create the chart plotSankey(data=xx,            from=\"groups\",            to=\"level1\",            value=\"frequency\") }"},{"path":"https://rodrodr.github.io/tenet/reference/plotSolar.html","id":null,"dir":"Reference","previous_headings":"","what":"Solar Network Centrality Plot — plotSolar","title":"Solar Network Centrality Plot — plotSolar","text":"plotSolar function generates circular solar centrality plot visualize relative centrality rank variation nodes network.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSolar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Solar Network Centrality Plot — plotSolar","text":"","code":"plotSolar(           data,            from=\"from\",            to=\"to\",            value=\"value\",           title=\"**Solar Network Centrality Plot**\",           subtitle=\"Relative Centrality and Rank Variation of Nodes in a Network.\",           caption=\"Own elaboration using network centrality ranks.\",           value.lab=\"Mentions\",           directed=FALSE,           pos.jitter=0,           palette=c(\"#FF0000\",                     \"#00A08A\",                     \"#F2AD00\",                     \"#F98400\",                     \"#5BBCD6\"),           center.col=\"red2\",           center.radius=0.05,           orbit.line.col=\"grey90\",           orbit.line.type=\"dotted\",           orbit.line.width=0.5,           arc.line.width=0.5,           start.line.col=\"purple\",           start.line.width=0.5,           start.line.type=\"dotted\",           legend.position=\"bottom\",           legend.justification=\"left\"           )"},{"path":"https://rodrodr.github.io/tenet/reference/plotSolar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Solar Network Centrality Plot — plotSolar","text":"data data.frame three columns: , , value. character specifying column name representing source nodes network (default: \"\"). character specifying column name representing target nodes network (default: \"\"). value character specifying column name representing node values (default: \"value\"). title character specifying plot title (default: \"**Solar Network Centrality Plot**\"). subtitle character specifying plot subtitle (default: \"Relative Centrality Rank Variation Nodes Network.\"). caption character specifying plot caption describing data source centrality measures used (default: \"elaboration using network centrality ranks.\"). value.lab character specifying label node values (default: \"Mentions\"). directed logical value indicating whether network directed (default: FALSE). pos.jitter numeric value specifying amount jitter node positions (default: 0). palette vector color codes specifying node colors (default: palette five colors: \"#FF0000\", \"#00A08A\", \"#F2AD00\", \"#F98400\", \"#5BBCD6\"). center.col character specifying color central node (default: \"red2\"). center.radius numeric value specifying radius central node (default: 0.05). orbit.line.col character specifying color orbit lines (default: \"grey90\"). orbit.line.type character specifying type orbit lines (default: \"dotted\"). orbit.line.width numeric value specifying width orbit lines (default: 0.5). arc.line.width numeric value specifying width lines representing orbit arcs (default: 0.5). start.line.col character specifying color starting lines (default: \"purple\"). start.line.width numeric value specifying width starting lines (default: 0.5). start.line.type character specifying type starting lines (default: \"dotted\"). legend.position character specifying position legend (default: \"bottom\"). legend.justification character specifying justification legend (default: \"left\").","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSolar.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Solar Network Centrality Plot — plotSolar","text":"plotSolar function takes network represented data frame calculates centrality measures (degree, closeness, betweenness, eigenvector, PageRank) nodes. generates circular plot resembling solar system, nodes positioned radially based centrality ranks. size color nodes, well color style lines, can customized using function arguments.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSolar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Solar Network Centrality Plot — plotSolar","text":"function returns ggplot2 plot object.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSolar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Solar Network Centrality Plot — plotSolar","text":"","code":"if (FALSE) { # Prepares the data library(quanteda) library(tenet)  # Creates a corpus from speeches cp <- corpus(spa.inaugural)  # Reshape the corpus according to  # sentences cs <- corpus_reshape(cp, \"sentences\")  # Calculates the frequency of terms # contained in the dic.pol.es dictionary d1 <- matchCodes(cs,                   dic.pol.es,                   level = 2,                   quietly=TRUE)  # Order the results d1 <- d1[order(d1$value, decreasing = T),]  # Plots the chart plotSolar(           d1,            pos.jitter = 0.01,            from = \"term1\",            to = \"term2\",            value = \"value\") }"},{"path":"https://rodrodr.github.io/tenet/reference/plotSpike.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexical Dispersion Plot for Large Corpora of Texts — plotSpike","title":"Lexical Dispersion Plot for Large Corpora of Texts — plotSpike","text":"function creates lexical dispersion plot large corpus objects based keywords dictionaries.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSpike.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexical Dispersion Plot for Large Corpora of Texts — plotSpike","text":"","code":"plotSpike(data=NULL,            palette=c(\"#017a4a\",                     \"#9F248F\",                     \"#FFCE4E\",                     \"#244579\",                     \"#c6242d\"),            doc_id=\"name\",           index_var=\"index\",           word_var=\"word\",           group_var=\"group\",           top_n=NULL,            sort=FALSE,           polar=TRUE,            quartiles=FALSE,            text_label=NULL,            tooltip_values=NULL,            tooltip_doc=\"name\",           label.size=1,           ring.col=\"red3\",           ring.width=0.2,           line.width=0.1,           legend.position=\"top\",           legend.title=\"Group\",           title=\"Lexical Spike Plot\",           subtitle=\"Keyword dispersion in texts.\",           svg.height=5,           svg.width=6,           ncol=NULL,           nrow=NULL,           interactive=TRUE)"},{"path":"https://rodrodr.github.io/tenet/reference/plotSpike.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexical Dispersion Plot for Large Corpora of Texts — plotSpike","text":"data data frame containing data generated function filterWords plotted containing: name document, list keywords retrieved, relative position text (index), group dictionary category keyword belongs. palette vector colors used plot represent groups categories. doc_id name variable containing document identifier. default \"name\". index_var name variable containing index word text. default \"index\". word_var name variable containing keyword found corpus. default \"word\". group_var name variable containing group. default \"group\". top_n top number documents plotted. default NULL. sort logical value indicating whether documents sorted frequency terms found. default FALSE. polar logical value indicating whether plot circular rectangular. default TRUE. quartiles logical value indicating whether quartiles plotted. default FALSE. text_label variable containing text labeling documents. default NULL. tooltip_values variable displays individual values tooltip. default NULL (values automatically generated function). tooltip_doc variable indicating text shown tooltip. default \"name\". label.size size labels. ring.col color ring. default \"red3\". ring.width width ring. default 0.2. line.width width lines. default 0.1. legend.position position legend. default \"top\". legend.title title legend. default \"Group\". title title plot. default \"Lexical Spike Plot\". subtitle subtitle plot. default \"Keyword dispersion texts.\" svg.height height svg interactive chart. default 5. svg.width width svg interactive chart. default 6. ncol number columns graph. default NULL. nrow number rows graph. default NULL. interactive logical value indicating whether plot interactive. default TRUE.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSpike.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Lexical Dispersion Plot for Large Corpora of Texts — plotSpike","text":"function generates two types Lexical Dispersion Plot keywords dictionaries categories. represents position selected keywords dictionary categories, metadata values text forming corpus object. default type circular, alternative, rectangular, represents keyword positions linearly. purpose represent large volume texts allow users interact results.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSpike.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Lexical Dispersion Plot for Large Corpora of Texts — plotSpike","text":"chart representing dispersion terms concepts.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotSpike.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Lexical Dispersion Plot for Large Corpora of Texts — plotSpike","text":"","code":"if (FALSE) {  # Aggregate the text by session from  # The Spanish Parliament Speeches Corpus ag <- aggregate(list(text=spa.sessions$speech.text),                 by=list(session_number=spa.sessions$session.number),                 paste,                  collapse=\"\\n\")  # Paste zeros to the number to allow # sorting the sessions ag$session_number[nchar(ag$session_number)==1] <-  paste0(\"00\", ag$session_number[nchar(ag$session_number)==1])  ag$session_number[nchar(ag$session_number)==2] <-  paste0(\"0\", ag$session_number[nchar(ag$session_number)==2])  # Convert the results into a corpus object library(quanteda) cp <- corpus(ag,               docid_field = \"session_number\")   # Create a dictionary dic <- dictionary(   list(Territorio=c(\"federal\",\"estatuto\",\"nacionalismo\",                     \"regionalismo\",\"cataluña\",\"lengua\"),        Genero=c(\"violencia machista\",\"mujer\",\"violencia sexual\",                 \"aborto\",\"reproductivo\",\"género\",\"trans\"),        Memoria=c(\"memoria\",\"franquismo\",\"franquista\",\"dictadura\"),        COVID=c(\"covid\",\"pandemia\",\"muerte\")))   # Searche the keywords and their # position in each session ter <- filterWords(cp, dic)  # Define a proper description for naming # the sessions. ter$name <- paste0(\"Session \", ter$name)   # Plot the results plotSpike(data=ter,            legend.title=\"Tema:\",           title=\"Congreso de los Diputados - XIV Legislatura (2019-2023)\",           subtitle=\"Territorio, género, memoria y COVID en los debates de los plenos.\")  }"},{"path":"https://rodrodr.github.io/tenet/reference/plotStream-shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny bindings for mywidget — plotStream-shiny","title":"Shiny bindings for mywidget — plotStream-shiny","text":"Output render functions using mywidget within Shiny applications interactive Rmd documents.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotStream-shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny bindings for mywidget — plotStream-shiny","text":"","code":"plotStreamOutput(outputId, width = \"100%\", height = \"600px\")  renderplotStream(expr, env = parent.frame(), quoted = FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/plotStream-shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny bindings for mywidget — plotStream-shiny","text":"outputId output variable read width, height Must valid CSS unit (like '100%', '400px', 'auto') number, coerced string 'px' appended. expr expression generates mywidget env environment evaluate expr. quoted expr quoted expression (quote())? useful want save expression variable.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotStream.html","id":null,"dir":"Reference","previous_headings":"","what":"Stream Chart — plotStream","title":"Stream Chart — plotStream","text":"Generates Interactive Stream Chart.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotStream.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stream Chart — plotStream","text":"","code":"plotStream(data,             x=NULL,            y=NULL,            group = NULL,            palette = c(\"#DD8D29\",\"#E2D200\",\"#46ACC8\",\"#E58601\",\"#B40F20\"),            height=580,            elementId=\"chartdivstream\")"},{"path":"https://rodrodr.github.io/tenet/reference/plotStream.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stream Chart — plotStream","text":"data data.frame object containing data categories, timeline sequence events quantity. x name variable data containing information relative timeline sequence events. y name variable containing quantities represented. group name variable indicating groups aggregated categories. palette color palette employed represent groups. height height html panel pixels. default 580. elementId Name div element employed contain graph. useful use type graph multiple times markdown page, instance. default \"chartdivstream\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotStream.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stream Chart — plotStream","text":"function generates interactive Stream Chart. represents data along central baseline. similar area chart, splits values using central line reference.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotStream.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stream Chart — plotStream","text":"chart representing evolution time sequence variable html source code generated.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotStream.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stream Chart — plotStream","text":"","code":"if (FALSE) { # Select the most salient representatives for  # the Vox party ag <- spa.sessions[         spa.sessions$rep.name%in%           c(\"Abascal Conde, Santiago\",             \"Espinosa de los Monteros de Simón, Iván\",             \"Olona Choclán, Macarena\",                             \"Ortega Smith-Molina, Francisco Javier\"),]  # Create a variable of month for smoothing the data ag$month <- substr(ag$session.date,3,7)  # Aggregate words by representative and month ag <- aggregate(     list(words=ag$speech.tokens),        by=list(         month=ag$month,          rep=ag$rep.name,          party=ag$rep.party),        sum,        na.rm=T)  # Order the data by month ag <- ag[order(ag$month),]  # Create the chart plotStream(ag,             x=\"month\",             y=\"words\",             group = \"rep\") }"},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree-shiny.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny bindings for mywidget — plotVoronoiTree-shiny","title":"Shiny bindings for mywidget — plotVoronoiTree-shiny","text":"Output render functions using mywidget within Shiny applications interactive Rmd documents. Output render functions using mywidget within Shiny applications interactive Rmd documents.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree-shiny.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny bindings for mywidget — plotVoronoiTree-shiny","text":"","code":"plotVoronoiTreeOutput(outputId, width = \"100%\", height = \"500px\")  plotVoronoiTreeOutput(outputId, width = \"100%\", height = \"500px\")  renderplotVoronoiTree(expr, env = parent.frame(), quoted = FALSE)"},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree-shiny.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny bindings for mywidget — plotVoronoiTree-shiny","text":"outputId output variable read width, height Must valid CSS unit (like '100%', '400px', '500px') number, coerced string 'px' appended. expr expression generates mywidget env environment evaluate expr. quoted expr quoted expression (quote())? useful want save expression variable.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Voronoi Tree Diagram — plotVoronoiTree","title":"Voronoi Tree Diagram — plotVoronoiTree","text":"Creates amCharts Voronoi Tree Diagram visualiazing hierarchical data.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Voronoi Tree Diagram — plotVoronoiTree","text":"","code":"plotVoronoiTree(                 data,                 value_col=\"value\",                 height = 500,                 font.size = 11,                 font.size.parent = 25,                 hide.parent.label = FALSE,                 strokeWidth = 2,                 strokeWidthParent = 5,                 strokeColor = \"#000\",                 type = \"polygon\",                 cornerCount = 120,                 initialDepth=2,                 elementId = \"voronoitreediv\"               )"},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Voronoi Tree Diagram — plotVoronoiTree","text":"data data.frame three columns: groups, elements, value. value_col name variable containing frequency value represented. default \"value\". height height html panel pixels. default 500. font.size size label font pixels. default 11. font.size.parent size label font pixels groups. default 25. hide.parent.label Logical. Indicates labels groups hidden. default FALSE. strokeWidth width border elements. default 2. strokeWidthParent width border groups. default 5. strokeColor color border elements groups hexadecimal. default black: \"#000\". type type graph created: \"rectangle\" \"polygon\". default \"polygon\". cornerCount number corners sides type polygon. triangle cornerCount=3, square: cornerCount=4, pentagon: cornerCount=5, hexagon: cornerCount=6, . default 120 (circle). initialDepth Defines depth information displayed chart rendered. initialDepth=1 shows top category second-level details informed clicked. initialDepth=2 shows first second-level categories . first choice makes graph easier read, second provides nice visual second-level categores many. default 2. elementId Name div element employed contain graph. useful use type graph multiple times markdown page, instance. default \"voronoitreediv\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Voronoi Tree Diagram — plotVoronoiTree","text":"function generates interactive Voronoi Tree Diagram representing hierarchical data. allows users explore textual data, codings themes intuitively.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Voronoi Tree Diagram — plotVoronoiTree","text":"Voronoi Tree diagram.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/plotVoronoiTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Voronoi Tree Diagram — plotVoronoiTree","text":"","code":"if (FALSE) { # Prepares the data library(quanteda) cp <- corpus(spa.inaugural)      dic <- dic.pol.es      xx <- countKeywords(cp,                      dic.pol.es,                      rel.freq = F,                      group.var = \"President\")      xx <- aggregate(list(frequency=xx$frequency),                  by=list(groups=xx$groups,                          level1=xx$level1,                         level2=xx$level2),                  sum, na.rm=T)      # Generates a circle voronoi tree diagram plotVoronoiTree(xx,                  value_col = \"frequency\")                      # Rectangle  plotVoronoiTree(xx,                  value_col = \"frequency\",                 type = \"rectangle\")      # Triangle  plotVoronoiTree(xx,                  value_col = \"frequency\",                 cornerCount= 3) }"},{"path":"https://rodrodr.github.io/tenet/reference/selColors.html","id":null,"dir":"Reference","previous_headings":"","what":"Large-Number Color Palettes for Graphs — selColors","title":"Large-Number Color Palettes for Graphs — selColors","text":"Generates color scales large number colors based custom basic palettes contained packages RColorBrewer wesanderson.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/selColors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Large-Number Color Palettes for Graphs — selColors","text":"","code":"selColors(palette=c(\"#1B9E77\",                     \"#D95F02\",                     \"#7570B3\",                     \"#E7298A\",                     \"#66A61E\",                     \"#E6AB02\",                     \"#A6761D\",                     \"#666666\"),            col.n=9)"},{"path":"https://rodrodr.github.io/tenet/reference/selColors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Large-Number Color Palettes for Graphs — selColors","text":"palette color palette included pal object. default colors \"Dark2\" palette included RColorBrewer package. col.n Total number colors generated. default 9.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/selColors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Large-Number Color Palettes for Graphs — selColors","text":"Generates color scales large number colors based custom basic palettes contained R packages.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/selColors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Large-Number Color Palettes for Graphs — selColors","text":"function returns list n colors based previously defined palette.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/selColors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Large-Number Color Palettes for Graphs — selColors","text":"","code":"if (FALSE) {  # Generates a list of 20 different colors based  # on the Dark2 palette (RColorBrewer) selColors(col.n=20)  # Generates a list of 20 different colors based  # on the \"ZissouContinuous\" palette (wesanderson) selColors(palette=pal$cat.wesanderson.ZissouContinuous.11, 20)   # Generates a list of 20 different colors based  # on a custom palette using red, yellow and blue selColors(palette=c(\"red\",\"yellow\",\"blue\"), col.n=20)   }"},{"path":"https://rodrodr.github.io/tenet/reference/spa.inaugural.html","id":null,"dir":"Reference","previous_headings":"","what":"Spanish Presidents' Inaugural Speeches — spa.inaugural","title":"Spanish Presidents' Inaugural Speeches — spa.inaugural","text":"dataset contains 16 Inaugural Speeches 1979 2023.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/spa.inaugural.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spanish Presidents' Inaugural Speeches — spa.inaugural","text":"","code":"spa.inaugural"},{"path":"https://rodrodr.github.io/tenet/reference/spa.inaugural.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Spanish Presidents' Inaugural Speeches — spa.inaugural","text":"data.frame object following variables: doc_id character; Document ID text character; Text inaugural speech President character; Name President gave speech Legislature numeric; number legislature","code":""},{"path":"https://rodrodr.github.io/tenet/reference/spa.inaugural.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Spanish Presidents' Inaugural Speeches — spa.inaugural","text":"Moncloa.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/spa.inaugural.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spanish Presidents' Inaugural Speeches — spa.inaugural","text":"","code":"# some operations on the corpus summary(spa.inaugural) #>     doc_id              text            President          Legislature     #>  Length:16          Length:16          Length:16          Min.   : 1.000   #>  Class :character   Class :character   Class :character   1st Qu.: 3.750   #>  Mode  :character   Mode  :character   Mode  :character   Median : 7.500   #>                                                           Mean   : 7.562   #>                                                           3rd Qu.:11.250   #>                                                           Max.   :15.000"},{"path":"https://rodrodr.github.io/tenet/reference/spa.sessions.html","id":null,"dir":"Reference","previous_headings":"","what":"Legislative Interventions on the 14th Legislature of the Spanish Congress (2019-2023) — spa.sessions","title":"Legislative Interventions on the 14th Legislature of the Spanish Congress (2019-2023) — spa.sessions","text":"dataset contains interventions lower-chamber representatives Spanish Congress (Congreso de los diputados) 14th legislature (2019-2023). observation corresponds intervention.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/spa.sessions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Legislative Interventions on the 14th Legislature of the Spanish Congress (2019-2023) — spa.sessions","text":"","code":"spa.sessions"},{"path":"https://rodrodr.github.io/tenet/reference/spa.sessions.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Legislative Interventions on the 14th Legislature of the Spanish Congress (2019-2023) — spa.sessions","text":"data.frame object following variables: leg.number integer; number legislature. session.date date; Date session carried . session.type character; type session: \"Plenaria\" (floor) \"Diputación Permanente\". session.number integer; sequential number assigned identify session. issue.type character; type issues discussed proceedings (voting, debate, questioning control). issue.details character; Details issues questions addressed intervention representative. speech.order integer; number indicating sequence intervention session. speech.text character; complete text intervention. rep.name character; full name representative intervention. rep.district character; electoral district representative. rep.party character; electoral party representative. rep.group character; parliamentary group representative. rep.condition character; \"place speech\" representative (representative, candidate, state minister, president, member parliament board). rep.institution character; institution representative belongs (lower chamber, particular ministry, presidential office). speech.tokens integer; number tokens speech.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/spa.sessions.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Legislative Interventions on the 14th Legislature of the Spanish Congress (2019-2023) — spa.sessions","text":"elaboration based legislative diaries provided Congreso de los Diputados (www.congreso.es).","code":""},{"path":"https://rodrodr.github.io/tenet/reference/spa.sessions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Legislative Interventions on the 14th Legislature of the Spanish Congress (2019-2023) — spa.sessions","text":"","code":"# some operations on the corpus summary(spa.sessions) #>   leg.number         session.date        session.type       session.number  #>  Length:43410       Min.   :2019-12-03   Length:43410       Min.   :  1.0   #>  Class :character   1st Qu.:2021-01-25   Class :character   1st Qu.: 64.0   #>  Mode  :character   Median :2021-11-24   Mode  :character   Median :132.0   #>                     Mean   :2021-10-27                      Mean   :130.2   #>                     3rd Qu.:2022-09-14                      3rd Qu.:197.0   #>                     Max.   :2023-06-07                      Max.   :262.0   #>   issue.type        issue.details       speech.order    speech.text        #>  Length:43410       Length:43410       Min.   :  1.00   Length:43410       #>  Class :character   Class :character   1st Qu.: 41.00   Class :character   #>  Mode  :character   Mode  :character   Median : 85.00   Mode  :character   #>                                        Mean   : 95.84                      #>                                        3rd Qu.:140.00                      #>                                        Max.   :393.00                      #>    rep.name         rep.district        rep.party          rep.group         #>  Length:43410       Length:43410       Length:43410       Length:43410       #>  Class :character   Class :character   Class :character   Class :character   #>  Mode  :character   Mode  :character   Mode  :character   Mode  :character   #>                                                                              #>                                                                              #>                                                                              #>  rep.condition      rep.institution    speech.tokens     #>  Length:43410       Length:43410       Min.   :    2.0   #>  Class :character   Class :character   1st Qu.:   18.0   #>  Mode  :character   Mode  :character   Median :   44.0   #>                                        Mean   :  319.1   #>                                        3rd Qu.:  394.0   #>                                        Max.   :23085.0   head(spa.sessions) #>       leg.number session.date session.type session.number issue.type #> 43334         14   2019-12-03     Plenaria              1      Otros #> 43073         14   2019-12-03     Plenaria              1      Otros #> 43333         14   2019-12-03     Plenaria              1      Otros #> 43137         14   2019-12-03     Plenaria              1      Otros #> 43332         14   2019-12-03     Plenaria              1      Otros #> 3818          14   2019-12-03     Plenaria              1      Otros #>                    issue.details speech.order #> 43334 — ELECCION DEL PRESIDENTE.            1 #> 43073 — ELECCION DEL PRESIDENTE.            2 #> 43333 — ELECCION DEL PRESIDENTE.            3 #> 43137 — ELECCION DEL PRESIDENTE.            4 #> 43332 — ELECCION DEL PRESIDENTE.            5 #> 3818  — ELECCION DEL PRESIDENTE.            6 #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              speech.text #> 43334                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Señorías, se va a proceder ahora a la elección de la Mesa del Congreso de los Diputados, según el procedimiento previsto en el artículo 37 del Reglamento. En primer lugar, se elegirá al presidente de la Cámara. La votación tendrá carácter secreto y se realizará por papeletas. Cada diputado escribirá solo un nombre en la papeleta.\\nResultará elegido el que obtenga el voto de la mayoría absoluta de los miembros de la Cámara. Si ninguno obtuviera en la primera votación dicha mayoría se repetirá la elección entre los que hayan alcanzado las dos mayores votaciones y resultará elegido el que obtenga más votos.\\nPor la señora secretaria de la Mesa de Edad se procederá al llamamiento por orden alfabético de las señoras y señores diputados para que depositen la papeleta en la urna correspondiente. Los miembros de la Mesa votarán al final.\\nComienza la votación.\\nPor las secretarias de la Mesa de Edad, señoras Rosique i Saltor y Muñoz Dalda, se procede al llamamiento de las señoras y los señores diputados, quienes van depositando sus papeletas en la urna.\\nUn segundo, señorías, por favor.\\n(La señora Lastra Fernández se ha hecho daño en un tobillo al bajar las escaleras).\\nDoña Adriana Lastra, no traiga usted el voto. Si va a permanecer en la sala, hágalo sentada e iremos a recogérselo. Si no, salga para que la atiendan y esperaremos hasta el final para que nos lo dé.\\nPor las secretarias de la Mesa de Edad, señoras Rosique i Saltor y Muñoz Dalda, se continúa con el llamamiento de las señoras y los señores diputados, quienes van depositando sus papeletas en la urna.\\nMuchísimas gracias. Han sido ustedes ejemplares. Hemos mejorado muchísimo.\\nAhora vamos a recoger los votos de los heridos —yo también estoy un poco mancado del remo derecho—, así que esto nos incrementará los tiempos muertos; digamos demediados, no muertos.\\n(Pausa).\\nTerminada la votación, dijo\\nSeñorías, ¿hay alguna señora diputada o algún señor diputado que no haya sido llamado para votar? (Denegaciones).\\nRealizado el escrutinio, dijo\\nEn consecuencia, tras realizar el escrutinio de los votos emitidos, el resultado es el siguiente: votos emitidos, 349; 167, a favor de doña Meritxell Batet Lamaña; 91, a favor de doña Ana María Pastor Julián; 52, a favor de doña Macarena Olona Choclán; 11 votos en blanco, y 28 votos nulos. Al no haberse obtenido el voto de la mayoría absoluta de los miembros de la Cámara, 176, y de acuerdo con lo dispuesto en el inciso final del artículo 37.1 del Reglamento, se ha de proceder a una nueva votación entre los que hayan alcanzado las dos mayores votaciones, resultando elegido el que obtenga más votos. En consecuencia, esta nueva votación se produce entre doña Meritxell Batet Lamaña y doña Ana María Pastor Julián, que son las diputadas que han obtenido mayor número de votos en la votación anterior. (Rumores). Resultará elegida presidenta del Congreso de los Diputados la que obtenga más votos. Si se produjera empate, se celebrarán sucesivas votaciones hasta que el empate quede dirimido. (Rumores). ¡Por favor, señorías!, que ya ven que me trafullo. Es la edad y el ronroneo. (Risas).\\nPor las señoras secretarias de la Mesa de Edad se procederá al llamamiento por orden alfabético de las señoras y los señores diputados para que depositen la papeleta en la urna correspondiente. Los miembros de la Mesa de Edad votarán al final.\\nComienza, pues, la votación.\\nPor las secretarias de la Mesa de Edad, señoras Rosique i Saltor y Muñoz Dalda, se procede al llamamiento de las señoras y los señores diputados, quienes van depositando sus papeletas en la urna.\\nTerminada la votación, dijo\\n¿Se ha omitido el nombre de algún diputado para la votación? #> 43073                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Sí. No me han llamado. #> 43333                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               No se la ha llamado. Pero ¿ha votado o no ha votado? #> 43137                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                No. #> 43332 No ha votado. Por favor, señoría, acérquese a identificarse para proceder a recoger su voto. (Así lo hace la señora Vehí Cantenys). Perdónenos, porque no sabe más el demonio por viejo; sabe menos. (Risas). ¿A alguien más hemos dejado sin nombrar? (Denegación). Pónganlo en mi debe; yo ya me ocuparé de poner algo en mi haber.\\nProcedemos al escrutinio.\\nRealizado el escrutinio, dijo\\nSeñorías, el resultado de la votación ha sido el siguiente: votos emitidos, 346; 166, a favor de doña Meritxell Batet Lamaña; 140, a favor de doña Ana María Pastor Julián; 11 votos en blanco, 29 votos nulos.\\nAl haber obtenido la mayoría de votos de los miembros de la Cámara, queda en consecuencia proclamada presidenta del Congreso de los Diputados doña Meritxell Batet Lamaña. (Prolongados aplausos de las señoras y los señores diputados, algunos puestos en pie).\\n— ELECCIÓN DE LOS VICEPRESIDENTES El señor PRESIDENTE DE LA MESA DE EDAD (Zamarrón Moreno): Se elegirán a continuación los cuatro vicepresidentes. Cada diputado escribirá solo un nombre en la papeleta para la elección de vicepresidentes. Resultarán elegidos por orden sucesivo como vicepresidentes los cuatro que obtengan mayor número de votos. Si en alguna votación se produjera empate, se celebrarán sucesivas votaciones entre los candidatos igualados en votos hasta que el empate quede dirimido. (Rumores). Señorías, esto es muy pesado pero es mi placer; guarden silencio.\\nPor las señoras secretarias de la Mesa de Edad, se procederá al llamamiento por orden alfabético de las señoras y los señores diputados para que depositen la papeleta en la urna correspondiente. Los miembros de la Mesa de Edad votarán al final.\\nSeñorías, comienza la votación.\\nPor las secretarias de la Mesa de Edad, señoras Rosique i Saltor y Muñoz Dalda, se procede al llamamiento de las señoras y los señores diputados, quienes van depositando sus papeletas en la urna.\\nTerminada la votación, dijo\\nSeñorías, silencio, por favor.\\n¿Alguna señora o señor diputado no ha sido nombrado para el voto? (Pausa). Al parecer, no; hemos mejorado. Vamos a proceder a recontarlos.\\nRealizado el escrutinio, dijo\\nSeñorías, el resultado de la votación para la elección de los cuatro vicepresidentes ha sido el siguiente: votos emitidos, 348; 108, a favor de don Alfonso Rodríguez Gómez de Celis; 101, a favor de doña Ana María Pastor Julián; 77, a favor de doña María Gloria Elizo Serrano; 52, a favor de don Ignacio Gil Lázaro; 1 voto en blanco y 9 votos nulos.\\nQuedan, en consecuencia, proclamados: vicepresidente primero, don Alfonso Rodríguez Gómez de Celis (aplausos de las señores y los señores diputados, algunos puestos en pie); vicepresidenta segunda, doña Ana María Pastor Julián (aplausos de las señoras y los señores diputados, algunos puestos en pie); vicepresidenta tercera, doña María Gloria Elizo Serrano (aplausos de las señores y los señores diputados, algunos puestos en pie); vicepresidente cuarto, don Ignacio Gil Lázaro (aplausos de las señoras y los señores diputados, algunos puestos en pie).\\n— ELECCIÓN DE LOS SECRETARIOS El señor PRESIDENTE DE LA MESA DE EDAD (Zamarrón Moreno): Señorías, se elegirán a continuación los cuatro secretarios. Cada diputado escribirá solo un nombre en la papeleta para la elección de secretarios. Resultarán elegidos por orden sucesivo como secretarios los cuatro que obtengan mayor número de votos. Si en alguna votación se produjera empate, se celebrarán sucesivas votaciones entre los candidatos igualados en votos hasta que el empate quede dirimido. (Rumores). ¡Señorías, por favor…!\\nEs el único placer que tengo: hacer estas lecturas.\\nPor las señoras secretarias de la Mesa de Edad se procederá al llamamiento por orden alfabético de las señoras y los señores diputados para que depositen la papeleta en la urna correspondiente. Los miembros de la Mesa de Edad votarán al final.\\nComienza la votación.\\nPor las secretarias de la Mesa de Edad, señoras Rosique i Saltor y Muñoz Dalda, se procede al llamamiento de las señoras y los señores diputados, quienes van depositando sus papeletas en la urna.\\nTerminada la votación y realizado el escrutinio, dijo\\nSeñorías, hago voto a su paciencia y a la propia.\\nEl resultado de la votación para la elección de los cuatro secretarios ha sido el siguiente: votos emitidos, 348; 67, a favor de doña Sofía Hernanz Costa; 67, a favor de don Gerardo Pisarello Prados; 60, a favor de don Javier Sánchez Serna; 58, a favor de don Adolfo Suárez Illana; 52, a favor de don José María Figaredo Álvarez-Sala; 43, a favor de don José María Espejo-Saavedra Conesa; 1 voto en blanco y cero votos nulos.\\nEn consecuencia, tenemos que proceder a una nueva elección para dirimir los puestos de doña Sofía Hernanz y don Gerardo Pisarello en orden a la ordinalidad —perdón por la redundancia— de los secretarios. (Rumores). Muestren ustedes y muestre mi espalda la mayor resignación. Así son las cosas y a hacerlo como manda el artículo 37.3 nos debemos. Cuanto antes lo hagamos antes terminamos. Señorías, paciencia y barajar. Procederemos de nuevo a la votación. Señorías, pueden votar lo que quieran, pero serán votos nulos aquellos que no correspondan a doña Sofía Hernanz Costa o a don Gerardo Pisarello Prados. La intención es simplemente saber quién será el primero y quién será el segundo, pero cuestiones de orden son necesarias para el orden.\\nSe me hace una propuesta que creo muy razonable, que vendrá bien para mis huesos y para los suyos, y es que hagamos un pequeño recreo de cinco minutos. Es pequeño, pero servirá para desentumecernos. Entonces, cinco minutos de reposo. Señorías, aprovechemos bien estos cinco minutos, son escasos; disfrutémoslos; estamos en muy buena compañía. (Pausa).\\nSeñorías, por favor, han pasado ya los cinco minutos que nos hemos concedido.\\nTengo estos ojos hechos a las penas / y a las cavilaciones estas sienes: / pena que vas, cavilación que vienes / como el mar de la playa a las arenas. Seguiremos amarrados a la dura galera turquesca —que presentó Góngora— en estos duros bancos, pero solo un poquito más. Señorías, vamos a dar inicio a esta votación extraordinaria para dirimir el puesto de los secretarios. Muchas gracias. Señoras secretarias, a la brega.\\nPor las secretarias de la Mesa de Edad, señoras Rosique i Saltor, y Muñoz Dalda, se procede al llamamiento de las señoras y los señores diputados, quienes van depositando sus papeletas en la urna.\\nTerminada la votación, dijo\\nComo estamos cansados, pasan algunas cosas, y ruego paciencia. Vuelvo a preguntar: ¿Algún diputado se ha quedado sin votar? (El señor Zaragoza Alonso levanta la mano). Que se acerque hacia nosotros, que no le vamos a hacer nada. (Risas.—Pausa).\\nRealizado el escrutinio, dijo\\nSeñorías, prestos al término de nuestra actuación, la Mesa de Edad quiere manifestarles su agradecimiento por la diligencia, el orden y su capacidad de disimular mis defectos y, sobre todo, por su buen humor, que nos ha sido preciso.\\nGracias. Ahora terminaremos enseguida, esta parte. (Aplausos.—Pausa).\\nSeñorías, el resultado de la votación para dirimir el empate entre los dos secretarios ha sido el siguiente: votos emitidos, 297; 91, a favor de don Gerardo Pisarello Prados; 87, a favor de doña Sofía Hernanz Costa. En consecuencia, quedan proclamados secretario primero, don Gerardo Pisarello Prados (aplausos de las señoras y los señores diputados, algunos puestos en pie); secretaria segunda, doña Sofía Hernanz Costa (aplausos de las señoras y los señores diputados, algunos puestos en pie); secretario tercero, don Javier Sánchez Serna (aplausos de las señoras y los señores diputados, algunos puestos en pie), y secretario cuarto, don Adolfo Suárez Illana (aplausos de las señoras y los señores diputados, algunos puestos en pie.—Rumores). Silencio, por favor.\\nPor tanto, ruego a la señora presidenta y a los señores vicepresidentes y secretarios elegidos en este acto que ocupen sus puestos en la Mesa del Congreso de los Diputados.\\nMuchísimas gracias y enhorabuena a los elegidos y a los electores. (Así lo hacen los nuevos miembros de la Mesa.—Aplausos). #> 3818                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Buenos días, señorías.\\nVamos a proceder al juramento o promesa de acatamiento de la Constitución de todos los miembros de la Cámara, en los términos previstos en el Reglamento de la misma. (La señora Álvarez de Toledo Peralta-Ramos pide la palabra).\\nSí, señora Álvarez de Toledo. #>                       rep.name rep.district rep.party #> 43334 Zamarrón Moreno, Agustín       Burgos      PSOE #> 43073    Vehí Cantenys, Mireia    Barcelona    CUP-PR #> 43333 Zamarrón Moreno, Agustín       Burgos      PSOE #> 43137    Vehí Cantenys, Mireia    Barcelona    CUP-PR #> 43332 Zamarrón Moreno, Agustín       Burgos      PSOE #> 3818   Batet Lamaña, Meritxell    Barcelona      PSOE #>                            rep.group      rep.condition #> 43334 Grupo Parlamentario Socialista Miembro de la mesa #> 43073      Grupo Parlamentario Mixto           Diputado #> 43333 Grupo Parlamentario Socialista Miembro de la mesa #> 43137      Grupo Parlamentario Mixto           Diputado #> 43332 Grupo Parlamentario Socialista Miembro de la mesa #> 3818  Grupo Parlamentario Socialista Miembro de la mesa #>                 rep.institution speech.tokens #> 43334 Congreso De Los Diputados           718 #> 43073 Congreso De Los Diputados             7 #> 43333 Congreso De Los Diputados            15 #> 43137 Congreso De Los Diputados             2 #> 43332 Congreso De Los Diputados          1573 #> 3818  Congreso De Los Diputados            55"},{"path":"https://rodrodr.github.io/tenet/reference/streamChart.html","id":null,"dir":"Reference","previous_headings":"","what":"Stream Chart — streamChart","title":"Stream Chart — streamChart","text":"Generates Interactive Stream Chart.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/streamChart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stream Chart — streamChart","text":"","code":"streamChart(data,              x=NULL,             y=NULL,             group = NULL,             url.return = FALSE,             html.return = FALSE,             viewer = TRUE,             palette = NULL,             height=580,             div.name=\"chartdivstream\")"},{"path":"https://rodrodr.github.io/tenet/reference/streamChart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stream Chart — streamChart","text":"data data.frame object containing data categories, timeline sequence events quantity. x name variable data containing information relative timeline sequence events. y name variable containing quantities represented. group name variable indicating groups aggregated categories. url.return Logical. Indicates function return url address html file. default FALSE. html.return Logical. Indicates function return html source code generated function. option useful wanting save results file. default FALSE. viewer Logical. Indicates function use RStudio viewer panel default browser display results. default TRUE. palette color palette employed chart. default  NULL (Dark2 RColorBrewer). height height html panel pixels. default 580. div.name Name div element employed contain graph. useful use type graph multiple times markdown page, instance. default \"chartdivstream\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/streamChart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stream Chart — streamChart","text":"function generates interactive Stream Chart. represents data along central baseline. similar area chart, splits values using central line reference.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/streamChart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stream Chart — streamChart","text":"chart representing evolution time sequence variable html source code generated.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/streamChart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stream Chart — streamChart","text":"","code":"if (FALSE) { # Select the most salient representatives for  # the Vox party ag <- spa.sessions[         spa.sessions$rep.name%in%           c(\"Abascal Conde, Santiago\",             \"Espinosa de los Monteros de Simón, Iván\",             \"Olona Choclán, Macarena\",                             \"Ortega Smith-Molina, Francisco Javier\"),]  # Create a variable of month for smoothing the data ag$month <- substr(ag$session.date,3,7)  # Aggregate words by representative and month ag <- aggregate(     list(words=ag$speech.tokens),        by=list(         month=ag$month,          rep=ag$rep.name,          party=ag$rep.party),        sum,        na.rm=T)  # Order the data by month ag <- ag[order(ag$month),]  # Create the chart streamChart(ag,              x=\"month\",              y=\"words\",              group = \"rep\") }"},{"path":"https://rodrodr.github.io/tenet/reference/tagCorpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Corpus Tagger — tagCorpus","title":"Corpus Tagger — tagCorpus","text":"Tags sentences, paragraphs textual units according categories contained dictionary.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagCorpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Corpus Tagger — tagCorpus","text":"","code":"tagCorpus(corpus,            dic,           reshape.dic=TRUE,           reshape.to=\"paragraphs\",           palette = c(\"#DD8D29\",\"#E2D200\",\"#46ACC8\",\"#E58601\",\"#B40F20\"),            bright = 130,           pagination = TRUE,            defaultPageSize=10,           show.details=TRUE,           case.insensitive=TRUE,           remove.accent=TRUE,           filter=FALSE,           data.return=FALSE,           quietly=TRUE)"},{"path":"https://rodrodr.github.io/tenet/reference/tagCorpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Corpus Tagger — tagCorpus","text":"corpus quanteda corpus containing one documents. dic dictionary used highlight tag submitted text. reshape.dic Logical. Indicates whether corpus reshaped . default TRUE. reshape.New document units corpus recast. default \"paragraphs\". options \"documents\" \"sentences\". palette color palette text highlighted. bright cutoff value color brightness define label text white black. default 130. pagination Indicates whether table organized according equal-sized pages. default TRUE. defaultPageSize Default page size (number elements) table. default 10. show.details Logical. Shows order text, document name, statistics terms categories. default TRUE. case.insensitive Logical. Indicates wether case taken account . default TRUE. remove.accent Logical. Indicates wether accents removed. default TRUE. filter Logical. Indicates wether texts without categories themes assigned filtered . default FALSE. data.return Logical. Defines data.frame classification texts returned instead interactive table. default FALSE. quietly Logical. Indicates wether progress bar used inform users progress. feature useful large corpuses. default TRUE.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagCorpus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Corpus Tagger — tagCorpus","text":"function tagCorpus finds highlights words expressions given text according dictionary. designed help qualitative researchers locate themes issues narrative texts documents. Therefore, meant exploratory tool qualitative analysis step broader coding process text.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagCorpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Corpus Tagger — tagCorpus","text":"function creates interactive table containing order element corpus, text, main category found text, categories, number matches, number themes present element.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagCorpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Corpus Tagger — tagCorpus","text":"","code":"if (FALSE) { # Create a corpus cp <- quanteda::corpus(spa.inaugural)  # Generate a dictionary with some keywords  # associated to themes dic <-quanteda::dictionary(     list(libertad=c(\"libert\",\"democr\",                     \"derecho\",\"libre\"),          cambio=c(\"cambi\",\"reform\",\"modern\",                   \"transform\",\"progres\",\"futuro\"),          justicia=c(\"justicia\",\"equidad\"),          patria=c(\"nacion\",\"pueblo\",\"espanol\")          ) )  # Create a table for sentences as  # units of analysis tagCorpus(cp,            dic=dic,            reshape.to = \"sentences\",            defaultPageSize = 5) }"},{"path":"https://rodrodr.github.io/tenet/reference/tagText.html","id":null,"dir":"Reference","previous_headings":"","what":"Text Tagger — tagText","title":"Text Tagger — tagText","text":"function tags text according keywords quanteda dictionaries.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagText.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Text Tagger — tagText","text":"","code":"tagText(text,          title=\"Document Title\",          keywords=NULL,         palette=c(\"#DD8D29\",\"#E2D200\",\"#46ACC8\",\"#E58601\",\"#B40F20\"),         bright=130,          tooltip=TRUE,          html.return=FALSE,          viewer=TRUE,          url.return=FALSE,          margin=50,          font.size=12)"},{"path":"https://rodrodr.github.io/tenet/reference/tagText.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Text Tagger — tagText","text":"text Text used tagging highlighting. title title header tagged document. default \"Document Title\". keywords keywords dictionary used highlight tag submitted text. default NULL. palette color palette text highlighted. bright Luminosity threshold separate bright dark colors. parameter passed colBright function. default 130. tooltip Logical. Indicates whether final document include tooltip containing dictionary categories . default TRUE. html.return Logical. TRUE, returns html code generated function stored saved file. default FALSE. viewer Logical. TRUE, show results RStudio Viewer panel. FALSE, opens file default browser. default TRUE. url.return Logical. TRUE, returns location temporary html file stored computer. default FALSE. margin Defines size html file margins pixels. default 50. font.size Establishes font size text represented. default 12.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagText.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Text Tagger — tagText","text":"function tagText finds highlights words expressions given text. designed help qualitative researchers locate themes issues narrative texts documents. Therefore, meant exploratory tool qualitative analysis step broader coding process text.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagText.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Text Tagger — tagText","text":"two possible values returned. first html code generated function. option particularly interesting case users plan save results file. becomes effective html.return=TRUE. second location temporary file generated function. becomes effective html.return=TRUE.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tagText.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Text Tagger — tagText","text":"","code":"if (FALSE) { # Create a text variable as example tx <- c(\"Political regimes can be classified  as liberal democracies, electoral democracies,  electoral autocracies, and full autocracies.\")  # Find words starting with \"democ\" in the text tagText(tx, keywords=\"democr\")   # Creates a dictionary to classify regimes regimes <- quanteda::dictionary(list(                   Democracy=c(\"democ\"),                   Autocracy=c(\"autoc\")                       ))  # Change the default colors tagText(tx, keywords=regimes) }"},{"path":"https://rodrodr.github.io/tenet/reference/tfRatio.html","id":null,"dir":"Reference","previous_headings":"","what":"Term-Frequency Ratio — tfRatio","title":"Term-Frequency Ratio — tfRatio","text":"Calculates ratio frequency term document compared appearance whole corpus.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tfRatio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Term-Frequency Ratio — tfRatio","text":"","code":"tfRatio(text,         keyword,         threshold=0,         return.selected=FALSE,         remove.accent=TRUE,         identifier=\"Latin-ASCII\"         )"},{"path":"https://rodrodr.github.io/tenet/reference/tfRatio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Term-Frequency Ratio — tfRatio","text":"text Collection text documents. keyword Keyword searched documents. threshold Defines limits selecting texts keyword particularly frequent texts. return.selected Logical. ratios values returned index documents accoding established threshold value. remove.accent Logical. accents removed text search? default TRUE. recommended remove accents using function case large number texts. identifier single string transform identifier, see stri_trans_list (stringi package), custom transliteration rules. default \"Latin-ASCII\".","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tfRatio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Term-Frequency Ratio — tfRatio","text":"Calculates ratio frequency given term compared appearance whole corpus. function particularly useful selecting texts according themes issues. allows users select documents containing ideas interest.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tfRatio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Term-Frequency Ratio — tfRatio","text":"function presents two possible values returned. default frequency ratio. ratio term high (much higher 1) cases documents concentrate occurence. zero texts matches 0 1 documents frequency average. option \"return.selected=TRUE\", function return values ratio limit established \"threshold\" argument. default last parameter return values 0, .e., texts term obsersed least .","code":""},{"path":"https://rodrodr.github.io/tenet/reference/tfRatio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Term-Frequency Ratio — tfRatio","text":"","code":"if (FALSE) { # Loads the dataset on US Presidential inaugural speeches tx <- quanteda::data_corpus_inaugural  # Calculates the ratio for the root \"democ\" in all documents tfRatio(text=tx, keyword=\"democ\")  # Select just those with the double of occurence of the # term than the average. tfRatio(text=tx,         keyword=\"democ\",         return.selected=TRUE,         threshold=2) }"},{"path":"https://rodrodr.github.io/tenet/reference/wordtree.html","id":null,"dir":"Reference","previous_headings":"","what":"Word Tree Chart — wordtree","title":"Word Tree Chart — wordtree","text":"Creates Google Chart's word tree visualizing terms context.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/wordtree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Word Tree Chart — wordtree","text":"","code":"wordtree(corpus,           keyword,           window=5,           direction=\"double\",           rm.stop=FALSE,           lang=\"es\",           url.return=FALSE,           height=900)"},{"path":"https://rodrodr.github.io/tenet/reference/wordtree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Word Tree Chart — wordtree","text":"corpus quanteda corpus object used word tree. keyword term used reference word tree. direction direction root. can either double (main targetWord), preffix (), suffix (). default \"double\". window number words put main term. default 5. rm.stop Logical. Defines stopwords removed.default FALSE. lang Language removing stopwords.default Spanish: \"es\". url.return Defines whether location html file returned.default TRUE. height height pixels html page containing chart. default 900 pixels.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/wordtree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Word Tree Chart — wordtree","text":"function creates word tree chart exploring keywords context.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/wordtree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Word Tree Chart — wordtree","text":"result html file opened browser location local computer.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/wordtree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Word Tree Chart — wordtree","text":"","code":"if (FALSE) { # Loads the dataset on US Presidential inaugural speeches tx <- quanteda::data_corpus_inaugural  # Find the context for the word \"democracy\" in the texts wordtree(tx, keyword=\"democracy\") }"},{"path":"https://rodrodr.github.io/tenet/reference/x_wordtree.html","id":null,"dir":"Reference","previous_headings":"","what":"Word Tree Html Generator — x_wordtree","title":"Word Tree Html Generator — x_wordtree","text":"Creates html code Google Chart's word tree visualizing terms context.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/x_wordtree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Word Tree Html Generator — x_wordtree","text":"","code":"x_wordtree(text,          targetWord,          direction=\"double\",          window=5,          height=900)"},{"path":"https://rodrodr.github.io/tenet/reference/x_wordtree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Word Tree Html Generator — x_wordtree","text":"text Text used word tree. targetWord Term used reference word tree. direction direction root. can either double (main targetWord), preffix (), suffix (). default \"double\". window number words put main term. default 5. height height pixels html page containing chart. default 900 pixels.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/x_wordtree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Word Tree Html Generator — x_wordtree","text":"ancillary function kwWordTree. generates final html code Google Chart's word tree.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/x_wordtree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Word Tree Html Generator — x_wordtree","text":"result html code chart.","code":""},{"path":"https://rodrodr.github.io/tenet/reference/x_wordtree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Word Tree Html Generator — x_wordtree","text":"","code":"if (FALSE) { # Loads the dataset on US Presidential inaugural speeches tx <- quanteda::data_corpus_inaugural  # Find the context for the word \"democracy\" in the texts x_wordtree(tx, targetWord=\"democracy\") }"}]
